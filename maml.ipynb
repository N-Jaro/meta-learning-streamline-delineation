{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","gpuType":"A100","mount_file_id":"14BSQvhvghVP51pgp40qnEddjIk55znya","authorship_tag":"ABX9TyMyn228ajJXX/aQJnn9V4Np"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["# Prepare the environment\n","\n"],"metadata":{"id":"Tn0eheaA7y6v"}},{"cell_type":"code","source":["%pip install segmentation-models &> /dev/null\n","%load_ext tensorboard\n","!wget https://raw.githubusercontent.com/N-Jaro/segmentation_model_tutorial/main/unet_util.py\n","!cp '/content/drive/MyDrive/Meta_learning_research/Notebooks/data_util.py' .\n","\n","# https://stackoverflow.com/questions/75433717/module-keras-utils-generic-utils-has-no-attribute-get-custom-objects-when-im\n","# open the file keras.py, change all the 'init_keras_custom_objects' to 'init_tfkeras_custom_objects'.\n","# the location of the keras.py is in the error message. In your case, it should be in /usr/local/lib/python3.8/dist-packages/efficientnet/\n","!wget https://raw.githubusercontent.com/N-Jaro/segmentation_model_tutorial/main/keras.py\n","!cp './keras.py' '/usr/local/lib/python3.10/dist-packages/efficientnet/keras.py'\n","!rm './keras.py'"],"metadata":{"id":"mQTQnaPLCw0j","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1694111778184,"user_tz":300,"elapsed":7720,"user":{"displayName":"Nattapon Jaroenchai","userId":"17092454241854925654"}},"outputId":"48a3a618-8ecd-4ed3-8977-ac9b4ec4fb78"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["--2023-09-07 18:36:15--  https://raw.githubusercontent.com/N-Jaro/segmentation_model_tutorial/main/unet_util.py\n","Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n","Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 12771 (12K) [text/plain]\n","Saving to: ‘unet_util.py’\n","\n","unet_util.py        100%[===================>]  12.47K  --.-KB/s    in 0s      \n","\n","2023-09-07 18:36:16 (76.6 MB/s) - ‘unet_util.py’ saved [12771/12771]\n","\n","--2023-09-07 18:36:17--  https://raw.githubusercontent.com/N-Jaro/segmentation_model_tutorial/main/keras.py\n","Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n","Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 711 [text/plain]\n","Saving to: ‘keras.py’\n","\n","keras.py            100%[===================>]     711  --.-KB/s    in 0s      \n","\n","2023-09-07 18:36:17 (61.5 MB/s) - ‘keras.py’ saved [711/711]\n","\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0SKZD8Eq74Io","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1694111782289,"user_tz":300,"elapsed":4113,"user":{"displayName":"Nattapon Jaroenchai","userId":"17092454241854925654"}},"outputId":"c7029d9d-7416-45fc-9b9e-3ea55fc356da"},"outputs":[{"output_type":"stream","name":"stdout","text":["Segmentation Models: using `keras` framework.\n","Python version:  3.10.12 (main, Jun 11 2023, 05:26:28) [GCC 11.4.0]\n","TensorFlow version:  2.12.0\n"]}],"source":["# Other dependencies\n","import random\n","import sys\n","import time\n","import shutil\n","import numpy as np\n","import tensorflow as tf\n","from keras import backend as K\n","import segmentation_models as sm\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.layers import Input, Conv2D\n","from tensorflow.keras.optimizers import Adam, SGD, RMSprop\n","from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, TensorBoard\n","from unet_util import dice_coef_loss, dice_coef, jacard_coef, dice_coef_loss, Residual_CNN_block, multiplication, attention_up_and_concatenate, multiplication2, attention_up_and_concatenate2, UNET_224, evaluate_prediction_result\n","from data_util import *\n","sm.set_framework('tf.keras')\n","sm.framework()\n","\n","# Reproduction\n","# np.random.seed(333)\n","\n","print('Python version: ', sys.version)\n","print('TensorFlow version: ', tf.__version__)\n"]},{"cell_type":"code","source":["%cd '/content/drive/MyDrive/Meta_learning_research/Notebooks/'\n","import os\n","input_data = './samples/'\n","model_path = './models/'\n","prediction_path = './predicts/'\n","log_path = './logs/'\n","\n","# Create the folder if it does not exist\n","os.makedirs(input_data, exist_ok=True)\n","os.makedirs(model_path, exist_ok=True)\n","os.makedirs(prediction_path, exist_ok=True)\n"],"metadata":{"id":"1SjFEhp33J4M","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1694111782289,"user_tz":300,"elapsed":16,"user":{"displayName":"Nattapon Jaroenchai","userId":"17092454241854925654"}},"outputId":"83fe9352-d572-4187-a6d5-108dfca1f72b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/Meta_learning_research/Notebooks\n"]}]},{"cell_type":"code","source":["# Avaiable backbones for Unet architechture\n","# 'vgg16' 'vgg19' 'resnet18' 'resnet34' 'resnet50' 'resnet101' 'resnet152' 'inceptionv3'\n","# 'inceptionresnetv2' 'densenet121' 'densenet169' 'densenet201' 'seresnet18' 'seresnet34'\n","# 'seresnet50' 'seresnet101' 'seresnet152', and 'attentionUnet'\n","backend = 'densenet121' # ResNet50 is the best model in the TL study\n","\n","# Added first Convo 8 to 3 channels layers to the random init model\n","name = 'maml-model-' + backend + '-' + str(np.random.randint(1000000))\n","\n","logdir = log_path + name\n","if(os.path.isdir(logdir)):\n","  shutil.rmtree(logdir)\n","os.makedirs(logdir, exist_ok=True)\n","\n","print('model location: '+ model_path+name+'.h5')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kv232Fbc9gm6","executionInfo":{"status":"ok","timestamp":1694111782289,"user_tz":300,"elapsed":13,"user":{"displayName":"Nattapon Jaroenchai","userId":"17092454241854925654"}},"outputId":"ea024712-6c62-4229-b0d7-3f85d2f39b0a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["model location: ./models/maml-model-densenet121-602361.h5\n"]}]},{"cell_type":"markdown","source":["# MAML Loop\n"],"metadata":{"id":"dFh2X6wN56_T"}},{"cell_type":"code","source":["# Create U-net model with the chosen backbone\n","# The U-net will be initialized with ImageNet weights and the ImageNet weights will be frozen\n","# in the first pass training\n","\n","if (backend==\"attentionUnet\"):\n","  # Attention U-net model\n","  learning_rate = 0.0000359\n","  unet_model = UNET_224()\n","  unet_model.compile(optimizer = Adam(learning_rate=learning_rate),\n","                loss = dice_coef_loss,\n","                metrics = [dice_coef,'accuracy'])\n","else:\n","  # Unet with ImageNet backends\n","  unet_model = sm.Unet(backend, classes = 1, encoder_weights=None, input_shape=(None, None, 8))\n","\n","  # Compile the model with 'Adam' optimizer (0.001 is the default learning rate) and define the loss and metrics\n","  unet_model.compile(optimizer = Adam(),\n","                loss = dice_coef_loss,\n","                metrics=[dice_coef,'accuracy'])\n","\n","# Train the unet model\n","# define hyperparameters and callback modules\n","patience = 10\n","maxepoch = 500\n","callbacks = [ReduceLROnPlateau(monitor='val_loss', factor=0.7, patience=patience, min_lr=1e-9, verbose=1, mode='min'),\n","            EarlyStopping(monitor='val_loss', patience=patience, verbose=0),\n","            ModelCheckpoint(model_path+name+'.h5', monitor='val_loss', save_best_only=True, verbose=0),\n","            TensorBoard(log_dir=logdir)]\n","\n","def f1_score(y_true, y_pred, epsilon=1e-7):\n","    \"\"\"\n","    Compute F1 loss.\n","\n","    Args:\n","    - y_true: Tensor of true labels. Shape (batch_size, d0, .. dN).\n","    - y_pred: Tensor of predicted labels. Shape (batch_size, d0, .. dN).\n","    - epsilon: Small number to prevent division by zero.\n","\n","    Returns:\n","    - f1_loss: F1 loss.\n","    \"\"\"\n","    # Just to make sure the prediction is in the range [0,1]\n","    y_pred = tf.clip_by_value(y_pred, clip_value_min=0, clip_value_max=1)\n","\n","    # Compute true positive, false positive, and false negative counts\n","    tp = tf.reduce_sum(y_true * y_pred, axis=[i for i in range(1, len(y_pred.shape))])\n","    fp = tf.reduce_sum((1 - y_true) * y_pred, axis=[i for i in range(1, len(y_pred.shape))])\n","    fn = tf.reduce_sum(y_true * (1 - y_pred), axis=[i for i in range(1, len(y_pred.shape))])\n","\n","    # Compute precision and recall\n","    precision = tp / (tp + fp + epsilon)\n","    recall = tp / (tp + fn + epsilon)\n","\n","    # Compute F1 score\n","    f1 = 2 * (precision * recall) / (precision + recall + epsilon)\n","\n","    # Return the mean F1 score across the batch as a loss\n","    return 1 - tf.reduce_mean(f1)\n","\n","# MAML inner loop optimizer\n","optimizer = SGD()\n","\n","# MAML outer loop optimizer\n","outer_optimizer = Adam()\n","\n","# save the training history\n","train_history_all = []\n","\n","\n","\n","# MAML outer loop function\n","def outer_loop_fn(episodes, num_tasks):\n","    with tf.GradientTape(watch_accessed_variables=False) as tape:\n","      losses = []\n","      tape.watch(losses)\n","\n","      # Compute loss on multiple tasks\n","      losses = [inner_loop_fn(episodes[i]) for i in range(num_tasks)]\n","\n","      # Compute mean loss across tasks\n","      mean_loss = tf.reduce_mean(losses)\n","\n","      # Compute gradients for outer loop\n","      grads = tape.gradient(mean_loss, unet_model.trainable_variables)\n","\n","      # Apply gradients to U-net model\n","      outer_optimizer.apply_gradients(zip(grads, unet_model.trainable_variables))\n"],"metadata":{"id":"bXdKuplr595N"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"gO1SOiWLDghg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def inner_loop_fn(episode):\n","    with tf.GradientTape() as tape:\n","        # Forward pass through U-net model on support set\n","        support_logits = unet_model(episode['support_set_data'][:5].astype(np.float32))\n","\n","        # Compute F1-score loss for support set\n","        support_loss = f1_score(episode['support_set_labels'][:5].astype(np.float32), support_logits)\n","\n","    # Compute gradients for support set loss\n","    grads = tape.gradient(support_loss, unet_model.trainable_variables)\n","\n","    # Apply gradients to U-net model\n","    optimizer.apply_gradients(zip(grads, unet_model.trainable_variables))\n","\n","    # Now compute the loss on the query set after updating the model with support set gradients\n","    query_logits = unet_model(episode['query_set_data'][:5].astype(np.float32))\n","    query_loss = f1_score(episode['query_set_labels'][:5].astype(np.float32), query_logits)\n","\n","    return query_loss"],"metadata":{"id":"TjAf-iX5Jh1C"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# MAML inner loop function\n","def inner_loop_fn(episode):\n","\n","    def closure():\n","        with tf.GradientTape() as tape:\n","            # Forward pass through U-net model\n","            logits = unet_model(episode['query_set_data'][:5].astype(np.float32))\n","\n","            # Compute F1-score loss\n","            loss = f1_score(episode['query_set_labels'][:5].astype(np.float32), logits)\n","\n","        # Compute gradients\n","        grads = tape.gradient(loss, unet_model.trainable_variables)\n","\n","        # Apply gradients to U-net model\n","        optimizer.apply_gradients(zip(grads, unet_model.trainable_variables))\n","\n","        print(loss)\n","\n","        return loss\n","\n","    optimizer.minimize(closure, var_list=unet_model.trainable_variables)"],"metadata":{"id":"pBPVZF30IJn5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def outer_loop_fn(episodes, num_tasks):\n","    accumulated_grads = [tf.zeros_like(var) for var in unet_model.trainable_variables]\n","\n","    train_history = unet_model.fit(x = episode['support_set_data'].astype(np.float32),y = episode['support_set_labels'].astype(np.float32),\n","                              validation_data = (episode['query_set_data'].astype(np.float32), episode['query_set_labels'].astype(np.float32)),\n","                              batch_size = 16, epochs = maxepoch, verbose=1, callbacks = callbacks)\n","\n","    train_history_all.append(train_history)\n","\n","    for i in range(num_tasks):\n","        with tf.GradientTape(watch_accessed_variables=False) as tape:\n","            tape.watch(unet_model.trainable_variables)\n","\n","            loss = inner_loop_fn(episodes[i])\n","\n","            grads = tape.gradient(loss, unet_model.trainable_variables)\n","            accumulated_grads = [acc_grad + grad for acc_grad, grad in zip(accumulated_grads, grads)]\n","\n","    # Average the gradients over the number of tasks\n","    averaged_grads = [grad / num_tasks for grad in accumulated_grads]\n","\n","    # Apply gradients\n","    outer_optimizer.apply_gradients(zip(averaged_grads, unet_model.trainable_variables))\n"],"metadata":{"id":"clrXpB09DIKg"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Prepare data episodes"],"metadata":{"id":"FeqP3EbcSHPS"}},{"cell_type":"code","source":["%cd '/content/drive/MyDrive/Meta_learning_research/Notebooks/'\n","data_dir = './samples/'  # Replace with the path to your directory containing numpy files\n","locations_meta_training = ['Alexander', 'Rowancreek']\n","locations_meta_testing = ['Covington']\n","num_samples_per_location = 100  # Configure the number of samples per location\n","num_episodes = 10  # Number of episodes\n","\n","data_loader = MetaDataLoader(data_dir, num_samples_per_location)\n","\n","# Create multi episodes for meta-training\n","mate_train_episodes = data_loader.create_multi_episodes(num_episodes, locations_meta_training)\n","mate_test_episodes = data_loader.create_multi_episodes(num_episodes, locations_meta_testing)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"V2b6OJTVSGgj","executionInfo":{"status":"ok","timestamp":1694115679549,"user_tz":300,"elapsed":153969,"user":{"displayName":"Nattapon Jaroenchai","userId":"17092454241854925654"}},"outputId":"8a894332-29fd-48fe-f340-e674a9a80d06"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/Meta_learning_research/Notebooks\n"]}]},{"cell_type":"markdown","source":["## Training Loop"],"metadata":{"id":"kZPK2q5JU1Sk"}},{"cell_type":"code","source":["num_epochs = 10  # Configure the number of epochs\n","\n","# Training loop\n","for i in range(num_epochs):\n","    outer_loop_fn(mate_train_episodes, 2)\n","    print('Epoch: ' + str(i))"],"metadata":{"id":"Ui5Aiuk05-8x","colab":{"base_uri":"https://localhost:8080/","height":382},"executionInfo":{"status":"error","timestamp":1694115772496,"user_tz":300,"elapsed":10733,"user":{"displayName":"Nattapon Jaroenchai","userId":"17092454241854925654"}},"outputId":"9a65ea04-cf18-434f-a479-24656592c4c2"},"execution_count":null,"outputs":[{"output_type":"error","ename":"ResourceExhaustedError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)","\u001b[0;32m<ipython-input-37-00d7a1958412>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Training loop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mouter_loop_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmate_train_episodes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Epoch: '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-29-2959e857a616>\u001b[0m in \u001b[0;36mouter_loop_fn\u001b[0;34m(episodes, num_tasks)\u001b[0m\n\u001b[1;32m      6\u001b[0m             \u001b[0mtape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munet_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minner_loop_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepisodes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m             \u001b[0mgrads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munet_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-36-361314cb3ea3>\u001b[0m in \u001b[0;36minner_loop_fn\u001b[0;34m(episode)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;31m# Compute gradients for support set loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mgrads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msupport_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munet_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;31m# Apply gradients to U-net model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/backprop.py\u001b[0m in \u001b[0;36mgradient\u001b[0;34m(self, target, sources, output_gradients, unconnected_gradients)\u001b[0m\n\u001b[1;32m   1061\u001b[0m                           for x in output_gradients]\n\u001b[1;32m   1062\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1063\u001b[0;31m     flat_grad = imperative_grad.imperative_grad(\n\u001b[0m\u001b[1;32m   1064\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1065\u001b[0m         \u001b[0mflat_targets\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/imperative_grad.py\u001b[0m in \u001b[0;36mimperative_grad\u001b[0;34m(tape, target, sources, output_gradients, sources_raw, unconnected_gradients)\u001b[0m\n\u001b[1;32m     65\u001b[0m         \"Unknown value for unconnected_gradients: %r\" % unconnected_gradients)\n\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m   return pywrap_tfe.TFE_Py_TapeGradient(\n\u001b[0m\u001b[1;32m     68\u001b[0m       \u001b[0mtape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tape\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/backprop.py\u001b[0m in \u001b[0;36m_gradient_function\u001b[0;34m(op_name, attr_tuple, num_inputs, inputs, outputs, out_grads, skip_input_indices, forward_pass_name_scope)\u001b[0m\n\u001b[1;32m    144\u001b[0m       \u001b[0mgradient_name_scope\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mforward_pass_name_scope\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"/\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgradient_name_scope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 146\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mgrad_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmock_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mout_grads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    147\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgrad_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmock_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mout_grads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/ops/nn_grad.py\u001b[0m in \u001b[0;36m_FusedBatchNormV3Grad\u001b[0;34m(op, *grad)\u001b[0m\n\u001b[1;32m    924\u001b[0m \u001b[0;34m@\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRegisterGradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"FusedBatchNormV3\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    925\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_FusedBatchNormV3Grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 926\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0m_BaseFusedBatchNormGrad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    927\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/ops/nn_grad.py\u001b[0m in \u001b[0;36m_BaseFusedBatchNormGrad\u001b[0;34m(op, version, *grad)\u001b[0m\n\u001b[1;32m    904\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mversion\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    905\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"reserve_space_3\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 906\u001b[0;31m     \u001b[0mdx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdscale\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdoffset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrad_fun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    907\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdata_format\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34mb\"NCHW\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    908\u001b[0m       \u001b[0mdx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marray_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/ops/gen_nn_ops.py\u001b[0m in \u001b[0;36mfused_batch_norm_grad_v3\u001b[0;34m(y_backprop, x, scale, reserve_space_1, reserve_space_2, reserve_space_3, epsilon, data_format, is_training, name)\u001b[0m\n\u001b[1;32m   4632\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4633\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4634\u001b[0;31m       \u001b[0m_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4635\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4636\u001b[0m       \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mraise_from_not_ok_status\u001b[0;34m(e, name)\u001b[0m\n\u001b[1;32m   7260\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mraise_from_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7261\u001b[0m   \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\" name: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 7262\u001b[0;31m   \u001b[0;32mraise\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   7263\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mResourceExhaustedError\u001b[0m: {{function_node __wrapped__FusedBatchNormGradV3_device_/job:localhost/replica:0/task:0/device:GPU:0}} OOM when allocating tensor with shape[832] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc [Op:FusedBatchNormGradV3]"]}]},{"cell_type":"code","source":["# Use the trained U-net model to segment input image\n","segmented_image = unet_model(mate_test_episodes[0]['query_set_data'])\n","\n","np.save(prediction_path+name+'_predict.npy',segmented_image)"],"metadata":{"id":"OzgVeq_Y6LK-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from google.colab import runtime\n","runtime.unassign()"],"metadata":{"id":"OeLtgc-OtFfT"},"execution_count":null,"outputs":[]}]}