{"cells":[{"cell_type":"markdown","source":["# MAML Notebook\n","\n","The training process of MAML"],"metadata":{"id":"rkXk2QEYUUK6"}},{"cell_type":"markdown","source":["## 1. Load libraries\n"],"metadata":{"id":"frF9xHvIUZ2S"}},{"cell_type":"code","source":["%cd '/content/drive/MyDrive/Meta_learning_research/Notebooks/'\n","%pip install wandb\n","import os\n","import wandb\n","import numpy as np\n","import datetime\n","import tensorflow as tf\n","import matplotlib.pyplot as plt\n","from data_util import MetaDataLoader"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"T3CFt2HL1_jb","executionInfo":{"status":"ok","timestamp":1714774218332,"user_tz":300,"elapsed":9323,"user":{"displayName":"Nattapon Jaroenchai","userId":"17092454241854925654"}},"outputId":"bede2f4e-be51-4cd3-b6e2-27f5baa6cafa"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/Meta_learning_research/Notebooks\n","Requirement already satisfied: wandb in /usr/local/lib/python3.10/dist-packages (0.16.6)\n","Requirement already satisfied: Click!=8.0.0,>=7.1 in /usr/local/lib/python3.10/dist-packages (from wandb) (8.1.7)\n","Requirement already satisfied: GitPython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (3.1.43)\n","Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (2.31.0)\n","Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (5.9.5)\n","Requirement already satisfied: sentry-sdk>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (2.0.1)\n","Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (0.4.0)\n","Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from wandb) (6.0.1)\n","Requirement already satisfied: setproctitle in /usr/local/lib/python3.10/dist-packages (from wandb) (1.3.3)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb) (67.7.2)\n","Requirement already satisfied: appdirs>=1.4.3 in /usr/local/lib/python3.10/dist-packages (from wandb) (1.4.4)\n","Requirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (3.20.3)\n","Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n","Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from GitPython!=3.1.29,>=1.0.0->wandb) (4.0.11)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2024.2.2)\n","Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb) (5.0.1)\n"]}]},{"cell_type":"markdown","source":["## 2. Prepare training data\n","\n","Each episode is one location (task)."],"metadata":{"id":"Fq6bOp9EUevd"}},{"cell_type":"code","source":["data_dir = './samples/'  # Replace with the path to your directory containing numpy files\n","locations_meta_training = ['Alexander', 'Rowancreek']\n","locations_meta_testing = ['Covington']\n","num_samples_per_location = 25  # Configure the number of samples per location\n","num_episodes = 10  # Number of episodes\n","normalization_type='-1' # the lower end of the normalized range  (\"0\" or \"-1\")\n","data_loader = MetaDataLoader(data_dir, num_samples_per_location, normalization_type)"],"metadata":{"id":"uX4W6z-EBycO"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":123178,"status":"ok","timestamp":1714767435355,"user":{"displayName":"Nattapon Jaroenchai","userId":"17092454241854925654"},"user_tz":300},"id":"KGBx7ABKrw2X","outputId":"688f559e-c5f4-43ee-ba98-2d8dcdcf91a7"},"outputs":[{"output_type":"stream","name":"stdout","text":["Alexander\n","Alexander\n","Rowancreek\n","Rowancreek\n","Alexander\n","Rowancreek\n","Alexander\n","Rowancreek\n","Rowancreek\n","Alexander\n"]}],"source":["# Create multi episodes for meta-training\n","meta_train_episodes = data_loader.create_multi_episodes(num_episodes, locations_meta_training)"]},{"cell_type":"markdown","source":["## 3. Define the model\n","\n","We are using simple U-net model with 700K trainable variables.  "],"metadata":{"id":"ovUOaNkGUq3i"}},{"cell_type":"markdown","source":["### Define Dice_loss (same as F1-score)"],"metadata":{"id":"80274k9u2wOO"}},{"cell_type":"code","source":["# Dice coefficient (similar to F1 score but differentiable)\n","def dice_coefficient(y_true, y_pred):\n","    smooth = 1e-6  # Small constant to avoid division by zero\n","    y_true_f = tf.cast(tf.reshape(y_true, [-1]), tf.float32)\n","    y_pred_f = tf.cast(tf.reshape(y_pred, [-1]), tf.float32)\n","    intersection = tf.reduce_sum(y_true_f * y_pred_f)\n","    return (2. * intersection + smooth) / (tf.reduce_sum(y_true_f) + tf.reduce_sum(y_pred_f) + smooth)\n","\n","# Dice loss to be minimized\n","def dice_loss(y_true, y_pred):\n","    return 1 - dice_coefficient(y_true, y_pred)"],"metadata":{"id":"WZ0VmtfL2uJt"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Define Attention U-net model"],"metadata":{"id":"OLPZC3TV23BG"}},{"cell_type":"code","source":["from tensorflow.keras.layers import ( Input, Conv2D, BatchNormalization, Activation, Conv2DTranspose,\n","                                        MaxPooling2D, Layer, add, multiply, GlobalAveragePooling2D,\n","                                        Dense, Reshape, Multiply )\n","from tensorflow.keras.models import Model\n","import tensorflow.keras.backend as K\n","\n","class ChannelAttention(Layer):\n","    def __init__(self, reduction_ratio=8, **kwargs):\n","        super(ChannelAttention, self).__init__(**kwargs)\n","        self.reduction_ratio = reduction_ratio\n","\n","    def build(self, input_shape):\n","        channel = input_shape[-1]\n","        self.fc1 = Dense(channel // self.reduction_ratio, activation='relu', kernel_initializer='he_normal', use_bias=True, bias_initializer='zeros')\n","        self.fc2 = Dense(channel, activation='sigmoid', kernel_initializer='he_normal', use_bias=True, bias_initializer='zeros')\n","        super(ChannelAttention, self).build(input_shape)\n","\n","    def call(self, inputs):\n","        avg_pool = GlobalAveragePooling2D()(inputs)\n","        avg_pool = Reshape((1, 1, avg_pool.shape[1]))(avg_pool)\n","        fc1_out = self.fc1(avg_pool)\n","        fc2_out = self.fc2(fc1_out)\n","        scale = Multiply()([inputs, fc2_out])\n","        return scale\n","\n","    def compute_output_shape(self, input_shape):\n","        return input_shape\n","\n","    def get_config(self):\n","        config = super(ChannelAttention, self).get_config()\n","        config.update({'reduction_ratio': self.reduction_ratio})\n","        return config\n","\n","class SpatialAttention(Layer):\n","    def __init__(self, kernel_size=7, **kwargs):\n","        super(SpatialAttention, self).__init__(**kwargs)\n","        self.kernel_size = kernel_size\n","\n","    def build(self, input_shape):\n","        self.conv = Conv2D(1, self.kernel_size, padding='same', activation='sigmoid', kernel_initializer='he_normal', use_bias=False)\n","        super(SpatialAttention, self).build(input_shape)\n","\n","    def call(self, inputs):\n","        avg_pool = K.mean(inputs, axis=3, keepdims=True)\n","        max_pool = K.max(inputs, axis=3, keepdims=True)\n","        concat = K.concatenate([avg_pool, max_pool], axis=3)\n","        attention = self.conv(concat)\n","        return multiply([inputs, attention])\n","\n","    def compute_output_shape(self, input_shape):\n","        return input_shape\n","\n","    def get_config(self):\n","        config = super(SpatialAttention, self).get_config()\n","        config.update({'kernel_size': self.kernel_size})\n","        return config\n","\n","class AttentionUnet:\n","    def __init__(self, img_width=224, input_channels=8, output_mask_channels=1, filters=32, last_dropout=0.2):\n","        self.img_width = img_width\n","        self.input_channels = input_channels\n","        self.output_mask_channels = output_mask_channels\n","        self.filters = filters\n","        self.last_dropout = last_dropout\n","\n","    def residual_cnn_block(self, x, size, dropout=0.0, batch_norm=True):\n","        conv = Conv2D(size, (3, 3), padding='same')(x)\n","        if batch_norm:\n","            conv = BatchNormalization()(conv)\n","        conv = Activation('relu')(conv)\n","        conv = Conv2D(size, (3, 3), padding='same')(conv)\n","        if batch_norm:\n","            conv = BatchNormalization()(conv)\n","        conv = Activation('relu')(conv)\n","        return conv\n","\n","    def attention_up_and_concatenate(self, inputs, attention_type):\n","        g, x = inputs\n","        if attention_type == 'spatial':\n","            attention_layer = SpatialAttention()\n","        elif attention_type == 'channel':\n","            attention_layer = ChannelAttention()\n","        x = attention_layer(x)\n","        inter_channel = x.get_shape().as_list()[3]\n","        g = Conv2DTranspose(inter_channel, (3,3), strides=(2, 2), padding='same')(g)\n","        return add([g, x])\n","\n","    def build_model(self):\n","        inputs = Input((self.img_width, self.img_width, self.input_channels))\n","        filters = self.filters\n","\n","        conv_224 = self.residual_cnn_block(inputs, filters)\n","        pool_112 = MaxPooling2D(pool_size=(2, 2))(conv_224)\n","        conv_112 = self.residual_cnn_block(pool_112, filters * 2)\n","        pool_56 = MaxPooling2D(pool_size=(2, 2))(conv_112)\n","        conv_56 = self.residual_cnn_block(pool_56, filters * 4)\n","        pool_28 = MaxPooling2D(pool_size=(2, 2))(conv_56)\n","        conv_28 = self.residual_cnn_block(pool_28, filters * 8)\n","        pool_14 = MaxPooling2D(pool_size=(2, 2))(conv_28)\n","        conv_14 = self.residual_cnn_block(pool_14, filters * 16)\n","        pool_7 = MaxPooling2D(pool_size=(2, 2))(conv_14)\n","        conv_7 = self.residual_cnn_block(pool_7, filters * 32)\n","\n","        # Upsampling path\n","        up_14 = self.attention_up_and_concatenate([conv_7, conv_14], 'spatial')\n","        up_conv_14 = self.residual_cnn_block(up_14, filters * 16)\n","        up_28 = self.attention_up_and_concatenate([up_conv_14, conv_28], 'spatial')\n","        up_conv_28 = self.residual_cnn_block(up_28, filters * 8)\n","        up_56 = self.attention_up_and_concatenate([up_conv_28, conv_56], 'channel')\n","        up_conv_56 = self.residual_cnn_block(up_56, filters * 4)\n","        up_112 = self.attention_up_and_concatenate([up_conv_56, conv_112], 'channel')\n","        up_conv_112 = self.residual_cnn_block(up_112, filters * 2)\n","        up_224 = self.attention_up_and_concatenate([up_conv_112, conv_224], 'channel')\n","        up_conv_224 = self.residual_cnn_block(up_224, filters, dropout=self.last_dropout)\n","\n","        # Output layer\n","        conv_final = Conv2D(self.output_mask_channels, (1, 1), activation='sigmoid')(up_conv_224)\n","\n","        # Create model\n","        model = Model(inputs, conv_final, name=\"AttentionUnet\")\n","        return model\n"],"metadata":{"id":"g2qZ8uxL2L_U"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Define Simple U-net model"],"metadata":{"id":"JnBDzCSn26tR"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"8N7Jen0Errns"},"outputs":[],"source":["import tensorflow as tf\n","\n","class SimpleUNet:\n","    def __init__(self, input_shape=(224, 224, 8), num_classes=1):\n","        self.input_shape = input_shape\n","        self.num_classes = num_classes\n","\n","    def build_model(self):\n","        inputs = tf.keras.Input(shape=self.input_shape)\n","\n","        # Downsample\n","        c1 = tf.keras.layers.Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(inputs)\n","        c1 = tf.keras.layers.Dropout(0.1)(c1)\n","        c1 = tf.keras.layers.Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c1)\n","        p1 = tf.keras.layers.MaxPooling2D((2, 2))(c1)\n","\n","        # Bottleneck\n","        c5 = tf.keras.layers.Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(p1)\n","        c5 = tf.keras.layers.Dropout(0.2)(c5)\n","        c5 = tf.keras.layers.Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c5)\n","\n","        # Upsample\n","        u6 = tf.keras.layers.Conv2DTranspose(16, (2, 2), strides=(2, 2), padding='same')(c5)\n","        u6 = tf.keras.layers.concatenate([u6, c1])\n","        c6 = tf.keras.layers.Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u6)\n","        c6 = tf.keras.layers.Dropout(0.1)(c6)\n","        c6 = tf.keras.layers.Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c6)\n","\n","        # Output layer\n","        outputs = tf.keras.layers.Conv2D(self.num_classes, (1, 1), activation='sigmoid')(c6)\n","\n","        model = tf.keras.Model(inputs=inputs, outputs=outputs)\n","        return model"]},{"cell_type":"markdown","source":["## 4. Define the training process (MAML)"],"metadata":{"id":"wXurQDpVVroj"}},{"cell_type":"markdown","source":["### The training with constant LR\n"],"metadata":{"id":"goGl3RvRSReK"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"AFC7JyJhqcHi"},"outputs":[],"source":["\n","def train_task_model(model, inputs, outputs, learning_rate=0.001, momentum=0.5):\n","    optimizer = tf.keras.optimizers.SGD(learning_rate=learning_rate, momentum=momentum)\n","    with tf.GradientTape() as tape:\n","        predictions = model(inputs)\n","        loss = dice_loss(outputs, predictions)\n","    gradients = tape.gradient(loss, model.trainable_variables)\n","    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n","    return model, loss  # Return the updated model\n","\n","def maml_model(base_model, episodes, meta_lr=0.001, inner_lr=0.0035, momentum=0.9, meta_batch_size=1, inner_steps=10, epochs=10):\n","    meta_optimizer = tf.keras.optimizers.Adam(learning_rate=meta_lr)\n","\n","    for epoch in range(epochs):\n","        task_losses = []\n","        for batch_index in range(meta_batch_size):\n","            task_updates = []\n","            for episode_index, episode in enumerate(episodes):\n","                # Copy model for task-specific training\n","                model_copy = tf.keras.models.clone_model(base_model)\n","                model_copy.set_weights(base_model.get_weights())\n","\n","                print(f\"Epoch {epoch + 1}, Meta-batch {batch_index + 1}, Starting training on episode {episode_index + 1}\")\n","\n","                # Inner loop: Task-specific adjustments with momentum using support set\n","                support_data = episode[\"support_set_data\"]\n","                support_labels = episode[\"support_set_labels\"]\n","                for step in range(inner_steps):\n","                    model_copy, inner_loss= train_task_model(model_copy, support_data, support_labels, learning_rate=inner_lr, momentum=momentum)\n","                    print(f\" -- Inner step {step + 1}, Loss {inner_loss}\")\n","\n","                # Evaluate the adapted model on the query set\n","                query_data = episode[\"query_set_data\"]\n","                query_labels = episode[\"query_set_labels\"]\n","                val_predictions = model_copy(query_data)\n","                val_loss = dice_loss(query_labels, val_predictions)\n","                task_losses.append(val_loss.numpy())  # Record validation loss\n","                print(f\" -- Validation loss after adapting to episode {episode_index + 1}: {val_loss.numpy()}\")\n","\n","              # Compute gradients for meta-update using the base model's variables\n","                with tf.GradientTape() as meta_tape:\n","                    # Watch the copy's variables directly for changes\n","                    meta_tape.watch(model_copy.trainable_variables)\n","                    new_val_loss = dice_loss(query_labels, model_copy(query_data))\n","                gradients = meta_tape.gradient(new_val_loss, model_copy.trainable_variables)\n","\n","                # Map gradients back to the base model's variables\n","                mapped_gradients = [tf.identity(grad) for grad in gradients]\n","                task_updates.append((mapped_gradients, new_val_loss))\n","\n","            # Outer loop: Update the base model using aggregated gradients from all tasks\n","            if task_updates:\n","                num_variables = len(base_model.trainable_variables)\n","                mean_gradients = []\n","                for i in range(num_variables):\n","                    grads = [update[0][i] for update in task_updates if update[0][i] is not None]\n","                    if grads:\n","                        mean_grad = tf.reduce_mean(tf.stack(grads), axis=0)\n","                        mean_gradients.append(mean_grad)\n","                    else:\n","                        mean_gradients.append(None)  # Handle the case where all gradients for a variable are None\n","\n","                # Only apply gradients that are not None\n","                gradients_to_apply = [(grad, var) for grad, var in zip(mean_gradients, base_model.trainable_variables) if grad is not None]\n","                if gradients_to_apply:\n","                    meta_optimizer.apply_gradients(gradients_to_apply)\n","\n","        print(f\"Epoch {epoch + 1} completed, Mean Validation Loss across all episodes: {tf.reduce_mean(task_losses)}\")\n","\n","    return base_model"]},{"cell_type":"markdown","source":["### The training with dynamics LR\n","\n"],"metadata":{"id":"v8Cign8NSW_K"}},{"cell_type":"code","source":["def train_task_model(model, inputs, outputs, optimizer):\n","    with tf.GradientTape() as tape:\n","        predictions = model(inputs)\n","        loss = dice_loss(outputs, predictions)\n","    gradients = tape.gradient(loss, model.trainable_variables)\n","    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n","    return model, loss.numpy()\n","\n","def maml_model(base_model, episodes, initial_meta_lr=0.001, initial_inner_lr=0.001, decay_steps=1000, decay_rate=0.96, meta_batch_size=1, inner_steps=1, epochs=500, patience=15, save_path='models'):\n","\n","    date_time = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n","    name = f'maml_{inner_steps}_{epochs}_{meta_batch_size}_{date_time}_best_model'\n","    model_path = os.path.join(save_path, name)\n","    print(f'Initialize the Training process: {name}')\n","\n","    # Initialize WandB\n","    wandb.init(project=\"maml_experiment\",\n","               name = name,\n","               config={\n","                    \"initial_meta_lr\": initial_meta_lr,\n","                    \"initial_inner_lr\": initial_inner_lr,\n","                    \"decay_steps\": decay_steps,\n","                    \"decay_rate\": decay_rate,\n","                    \"meta_batch_size\": meta_batch_size,\n","                    \"inner_steps\": inner_steps,\n","                    \"epochs\": epochs,\n","                    \"patience\": patience,\n","                    \"model_path\": model_path,\n","                    \"model_type\": \"unet\"\n","                })\n","\n","\n","    # Define learning rate schedules\n","    inner_lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n","        initial_inner_lr, decay_steps, decay_rate, staircase=True)\n","    meta_lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n","        initial_meta_lr, decay_steps, decay_rate, staircase=True)\n","    meta_optimizer = tf.keras.optimizers.Adam(learning_rate=meta_lr_schedule)\n","\n","    best_loss = float('inf')\n","    no_improvement_count = 0  # Counter to track the number of epochs without improvement\n","\n","    for epoch in range(epochs):\n","        task_losses = []\n","        for batch_index in range(meta_batch_size):\n","            task_updates = []\n","            for episode_index, episode in enumerate(episodes):\n","                # Copy model for task-specific training\n","                model_copy = tf.keras.models.clone_model(base_model)\n","                model_copy.set_weights(base_model.get_weights())\n","\n","                inner_optimizer = tf.keras.optimizers.SGD(learning_rate=inner_lr_schedule(epoch * len(episodes) + episode_index))\n","\n","                # Inner loop: Task-specific adjustments with dynamic learning rate\n","                support_data = episode[\"support_set_data\"]\n","                support_labels = episode[\"support_set_labels\"]\n","                episode_losses = []\n","                for step in range(inner_steps):\n","                    model_copy, loss = train_task_model(model_copy, support_data, support_labels, inner_optimizer)\n","                    episode_losses.append(loss)\n","\n","                # Evaluate the adapted model on the query set\n","                query_data = episode[\"query_set_data\"]\n","                query_labels = episode[\"query_set_labels\"]\n","                val_predictions = model_copy(query_data)\n","                val_loss = dice_loss(query_labels, val_predictions)\n","                task_losses.append(val_loss.numpy())\n","\n","                wandb.log({\n","                    \"epoch\": epoch,\n","                    \"episode\": episode_index,\n","                    \"eps_loss\": tf.reduce_mean(episode_losses),\n","                    \"eps_val_loss\": val_loss.numpy()\n","                })\n","\n","                # Compute gradients for meta-update using the base model's variables\n","                with tf.GradientTape() as meta_tape:\n","                    meta_tape.watch(model_copy.trainable_variables)\n","                    new_val_loss = dice_loss(query_labels, model_copy(query_data))\n","                gradients = meta_tape.gradient(new_val_loss, model_copy.trainable_variables)\n","\n","                # Map gradients back to the base model's variables\n","                mapped_gradients = [tf.identity(grad) for grad in gradients]\n","                task_updates.append((mapped_gradients, new_val_loss))\n","\n","            # Outer loop: Update the base model using aggregated gradients from all tasks\n","            if task_updates:\n","                num_variables = len(base_model.trainable_variables)\n","                mean_gradients = []\n","                for i in range(num_variables):\n","                    grads = [update[0][i] for update in task_updates if update[0][i] is not None]\n","                    if grads:\n","                        mean_grad = tf.reduce_mean(tf.stack(grads), axis=0)\n","                        mean_gradients.append(mean_grad)\n","                    else:\n","                        mean_gradients.append(None)  # Handle the case where all gradients for a variable are None\n","\n","                gradients_to_apply = [(grad, var) for grad, var in zip(mean_gradients, base_model.trainable_variables) if grad is not None]\n","                if gradients_to_apply:\n","                    meta_optimizer.apply_gradients(gradients_to_apply)\n","\n","        mean_loss = tf.reduce_mean(task_losses)\n","        wandb.log({\n","            \"epoch\": epoch,\n","            \"mean_val_loss\": mean_loss\n","        })\n","\n","        # Early stopping and model saving\n","        if mean_loss < best_loss:\n","            best_loss = mean_loss\n","            no_improvement_count = 0\n","            base_model.save(model_path)  # Save the best model\n","            print(f\"Saved new best model with validation loss: {best_loss}\")\n","\n","        else:\n","            no_improvement_count += 1\n","            if no_improvement_count >= patience:\n","                print(f\"No improvement for {patience} consecutive epochs, stopping training.\")\n","                break  # Stop training if no improvement in 'patience' number of epochs\n","\n","        print(f\"Epoch {epoch + 1} completed, Mean Validation Loss across all episodes: {mean_loss}\")\n","\n","    wandb.finish()\n","    return base_model, name"],"metadata":{"id":"dqgu8Sf2SbWW"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 5. Train the model with the Meta-training set."],"metadata":{"id":"AZ7dH1wqVOhQ"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"uKYz0ed9rpNb","outputId":"bd13abab-1f5e-44ad-c171-ddebe20891a4"},"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"model\"\n","__________________________________________________________________________________________________\n"," Layer (type)                Output Shape                 Param #   Connected to                  \n","==================================================================================================\n"," input_1 (InputLayer)        [(None, 224, 224, 8)]        0         []                            \n","                                                                                                  \n"," conv2d (Conv2D)             (None, 224, 224, 16)         1168      ['input_1[0][0]']             \n","                                                                                                  \n"," dropout (Dropout)           (None, 224, 224, 16)         0         ['conv2d[0][0]']              \n","                                                                                                  \n"," conv2d_1 (Conv2D)           (None, 224, 224, 16)         2320      ['dropout[0][0]']             \n","                                                                                                  \n"," max_pooling2d (MaxPooling2  (None, 112, 112, 16)         0         ['conv2d_1[0][0]']            \n"," D)                                                                                               \n","                                                                                                  \n"," conv2d_2 (Conv2D)           (None, 112, 112, 64)         9280      ['max_pooling2d[0][0]']       \n","                                                                                                  \n"," dropout_1 (Dropout)         (None, 112, 112, 64)         0         ['conv2d_2[0][0]']            \n","                                                                                                  \n"," conv2d_3 (Conv2D)           (None, 112, 112, 64)         36928     ['dropout_1[0][0]']           \n","                                                                                                  \n"," conv2d_transpose (Conv2DTr  (None, 224, 224, 16)         4112      ['conv2d_3[0][0]']            \n"," anspose)                                                                                         \n","                                                                                                  \n"," concatenate (Concatenate)   (None, 224, 224, 32)         0         ['conv2d_transpose[0][0]',    \n","                                                                     'conv2d_1[0][0]']            \n","                                                                                                  \n"," conv2d_4 (Conv2D)           (None, 224, 224, 16)         4624      ['concatenate[0][0]']         \n","                                                                                                  \n"," dropout_2 (Dropout)         (None, 224, 224, 16)         0         ['conv2d_4[0][0]']            \n","                                                                                                  \n"," conv2d_5 (Conv2D)           (None, 224, 224, 16)         2320      ['dropout_2[0][0]']           \n","                                                                                                  \n"," conv2d_6 (Conv2D)           (None, 224, 224, 1)          17        ['conv2d_5[0][0]']            \n","                                                                                                  \n","==================================================================================================\n","Total params: 60769 (237.38 KB)\n","Trainable params: 60769 (237.38 KB)\n","Non-trainable params: 0 (0.00 Byte)\n","__________________________________________________________________________________________________\n","Initialize the Training process: maml_1_500_1_20240503_201907_best_model\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["\n","        window._wandbApiKey = new Promise((resolve, reject) => {\n","            function loadScript(url) {\n","            return new Promise(function(resolve, reject) {\n","                let newScript = document.createElement(\"script\");\n","                newScript.onerror = reject;\n","                newScript.onload = resolve;\n","                document.body.appendChild(newScript);\n","                newScript.src = url;\n","            });\n","            }\n","            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n","            const iframe = document.createElement('iframe')\n","            iframe.style.cssText = \"width:0;height:0;border:none\"\n","            document.body.appendChild(iframe)\n","            const handshake = new Postmate({\n","                container: iframe,\n","                url: 'https://wandb.ai/authorize'\n","            });\n","            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n","            handshake.then(function(child) {\n","                child.on('authorize', data => {\n","                    clearTimeout(timeout)\n","                    resolve(data)\n","                });\n","            });\n","            })\n","        });\n","    "]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n","\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n","wandb: Paste an API key from your profile and hit enter, or press ctrl+c to quit:"]},{"name":"stdout","output_type":"stream","text":[" ··········\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Tracking run with wandb version 0.16.6"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Run data is saved locally in <code>/content/drive/MyDrive/Meta_learning_research/Notebooks/wandb/run-20240503_201958-h18lgwab</code>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Syncing run <strong><a href='https://wandb.ai/9bombs/maml_experiment/runs/h18lgwab' target=\"_blank\">maml_1_500_1_20240503_201907_best_model</a></strong> to <a href='https://wandb.ai/9bombs/maml_experiment' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View project at <a href='https://wandb.ai/9bombs/maml_experiment' target=\"_blank\">https://wandb.ai/9bombs/maml_experiment</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run at <a href='https://wandb.ai/9bombs/maml_experiment/runs/h18lgwab' target=\"_blank\">https://wandb.ai/9bombs/maml_experiment/runs/h18lgwab</a>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:5 out of the last 5 calls to <function _BaseOptimizer._update_step_xla at 0x7dde3c3d95a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n","WARNING:tensorflow:6 out of the last 6 calls to <function _BaseOptimizer._update_step_xla at 0x7dde3c3d95a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n","WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"]},{"output_type":"stream","name":"stdout","text":["Saved new best model with validation loss: 0.9409248232841492\n","Epoch 1 completed, Mean Validation Loss across all episodes: 0.9409248232841492\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"]},{"output_type":"stream","name":"stdout","text":["Saved new best model with validation loss: 0.9346744418144226\n","Epoch 2 completed, Mean Validation Loss across all episodes: 0.9346744418144226\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"]},{"output_type":"stream","name":"stdout","text":["Saved new best model with validation loss: 0.927566647529602\n","Epoch 3 completed, Mean Validation Loss across all episodes: 0.927566647529602\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"]},{"output_type":"stream","name":"stdout","text":["Saved new best model with validation loss: 0.9184465408325195\n","Epoch 4 completed, Mean Validation Loss across all episodes: 0.9184465408325195\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"]},{"output_type":"stream","name":"stdout","text":["Saved new best model with validation loss: 0.9053918123245239\n","Epoch 5 completed, Mean Validation Loss across all episodes: 0.9053918123245239\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"]},{"output_type":"stream","name":"stdout","text":["Saved new best model with validation loss: 0.8863885998725891\n","Epoch 6 completed, Mean Validation Loss across all episodes: 0.8863885998725891\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"]},{"output_type":"stream","name":"stdout","text":["Saved new best model with validation loss: 0.8591081500053406\n","Epoch 7 completed, Mean Validation Loss across all episodes: 0.8591081500053406\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"]},{"output_type":"stream","name":"stdout","text":["Saved new best model with validation loss: 0.8217463493347168\n","Epoch 8 completed, Mean Validation Loss across all episodes: 0.8217463493347168\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"]},{"output_type":"stream","name":"stdout","text":["Saved new best model with validation loss: 0.7717688679695129\n","Epoch 9 completed, Mean Validation Loss across all episodes: 0.7717688679695129\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"]},{"output_type":"stream","name":"stdout","text":["Saved new best model with validation loss: 0.7100585699081421\n","Epoch 10 completed, Mean Validation Loss across all episodes: 0.7100585699081421\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"]},{"output_type":"stream","name":"stdout","text":["Saved new best model with validation loss: 0.6444177031517029\n","Epoch 11 completed, Mean Validation Loss across all episodes: 0.6444177031517029\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"]},{"output_type":"stream","name":"stdout","text":["Saved new best model with validation loss: 0.5865862369537354\n","Epoch 12 completed, Mean Validation Loss across all episodes: 0.5865862369537354\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"]},{"output_type":"stream","name":"stdout","text":["Saved new best model with validation loss: 0.5432615280151367\n","Epoch 13 completed, Mean Validation Loss across all episodes: 0.5432615280151367\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"]},{"output_type":"stream","name":"stdout","text":["Saved new best model with validation loss: 0.5119611024856567\n","Epoch 14 completed, Mean Validation Loss across all episodes: 0.5119611024856567\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"]},{"output_type":"stream","name":"stdout","text":["Saved new best model with validation loss: 0.48743677139282227\n","Epoch 15 completed, Mean Validation Loss across all episodes: 0.48743677139282227\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"]},{"output_type":"stream","name":"stdout","text":["Saved new best model with validation loss: 0.46768999099731445\n","Epoch 16 completed, Mean Validation Loss across all episodes: 0.46768999099731445\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"]},{"output_type":"stream","name":"stdout","text":["Saved new best model with validation loss: 0.4495214819908142\n","Epoch 17 completed, Mean Validation Loss across all episodes: 0.4495214819908142\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"]},{"output_type":"stream","name":"stdout","text":["Saved new best model with validation loss: 0.43353453278541565\n","Epoch 18 completed, Mean Validation Loss across all episodes: 0.43353453278541565\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"]},{"output_type":"stream","name":"stdout","text":["Saved new best model with validation loss: 0.4186418056488037\n","Epoch 19 completed, Mean Validation Loss across all episodes: 0.4186418056488037\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"]},{"output_type":"stream","name":"stdout","text":["Saved new best model with validation loss: 0.40500983595848083\n","Epoch 20 completed, Mean Validation Loss across all episodes: 0.40500983595848083\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"]},{"output_type":"stream","name":"stdout","text":["Saved new best model with validation loss: 0.391934871673584\n","Epoch 21 completed, Mean Validation Loss across all episodes: 0.391934871673584\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"]},{"output_type":"stream","name":"stdout","text":["Saved new best model with validation loss: 0.37920087575912476\n","Epoch 22 completed, Mean Validation Loss across all episodes: 0.37920087575912476\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"]},{"output_type":"stream","name":"stdout","text":["Saved new best model with validation loss: 0.3673875331878662\n","Epoch 23 completed, Mean Validation Loss across all episodes: 0.3673875331878662\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"]},{"output_type":"stream","name":"stdout","text":["Saved new best model with validation loss: 0.3570271134376526\n","Epoch 24 completed, Mean Validation Loss across all episodes: 0.3570271134376526\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"]},{"output_type":"stream","name":"stdout","text":["Saved new best model with validation loss: 0.35265636444091797\n","Epoch 25 completed, Mean Validation Loss across all episodes: 0.35265636444091797\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"]},{"output_type":"stream","name":"stdout","text":["Saved new best model with validation loss: 0.3481772840023041\n","Epoch 26 completed, Mean Validation Loss across all episodes: 0.3481772840023041\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"]},{"output_type":"stream","name":"stdout","text":["Saved new best model with validation loss: 0.33559709787368774\n","Epoch 27 completed, Mean Validation Loss across all episodes: 0.33559709787368774\n","Epoch 28 completed, Mean Validation Loss across all episodes: 0.3368086516857147\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"]},{"output_type":"stream","name":"stdout","text":["Saved new best model with validation loss: 0.3290213942527771\n","Epoch 29 completed, Mean Validation Loss across all episodes: 0.3290213942527771\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"]},{"output_type":"stream","name":"stdout","text":["Saved new best model with validation loss: 0.3280598521232605\n","Epoch 30 completed, Mean Validation Loss across all episodes: 0.3280598521232605\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"]},{"output_type":"stream","name":"stdout","text":["Saved new best model with validation loss: 0.3234453797340393\n","Epoch 31 completed, Mean Validation Loss across all episodes: 0.3234453797340393\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"]},{"output_type":"stream","name":"stdout","text":["Saved new best model with validation loss: 0.31802257895469666\n","Epoch 32 completed, Mean Validation Loss across all episodes: 0.31802257895469666\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"]},{"output_type":"stream","name":"stdout","text":["Saved new best model with validation loss: 0.31749358773231506\n","Epoch 33 completed, Mean Validation Loss across all episodes: 0.31749358773231506\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"]},{"output_type":"stream","name":"stdout","text":["Saved new best model with validation loss: 0.30921268463134766\n","Epoch 34 completed, Mean Validation Loss across all episodes: 0.30921268463134766\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"]},{"output_type":"stream","name":"stdout","text":["Saved new best model with validation loss: 0.3073142468929291\n","Epoch 35 completed, Mean Validation Loss across all episodes: 0.3073142468929291\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"]},{"output_type":"stream","name":"stdout","text":["Saved new best model with validation loss: 0.302977979183197\n","Epoch 36 completed, Mean Validation Loss across all episodes: 0.302977979183197\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"]},{"output_type":"stream","name":"stdout","text":["Saved new best model with validation loss: 0.297488272190094\n","Epoch 37 completed, Mean Validation Loss across all episodes: 0.297488272190094\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"]},{"output_type":"stream","name":"stdout","text":["Saved new best model with validation loss: 0.29652664065361023\n","Epoch 38 completed, Mean Validation Loss across all episodes: 0.29652664065361023\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"]},{"output_type":"stream","name":"stdout","text":["Saved new best model with validation loss: 0.29122599959373474\n","Epoch 39 completed, Mean Validation Loss across all episodes: 0.29122599959373474\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"]},{"output_type":"stream","name":"stdout","text":["Saved new best model with validation loss: 0.28808027505874634\n","Epoch 40 completed, Mean Validation Loss across all episodes: 0.28808027505874634\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"]},{"output_type":"stream","name":"stdout","text":["Saved new best model with validation loss: 0.28707608580589294\n","Epoch 41 completed, Mean Validation Loss across all episodes: 0.28707608580589294\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"]},{"output_type":"stream","name":"stdout","text":["Saved new best model with validation loss: 0.2828981280326843\n","Epoch 42 completed, Mean Validation Loss across all episodes: 0.2828981280326843\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"]},{"output_type":"stream","name":"stdout","text":["Saved new best model with validation loss: 0.28056350350379944\n","Epoch 43 completed, Mean Validation Loss across all episodes: 0.28056350350379944\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"]},{"output_type":"stream","name":"stdout","text":["Saved new best model with validation loss: 0.280374139547348\n","Epoch 44 completed, Mean Validation Loss across all episodes: 0.280374139547348\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"]},{"output_type":"stream","name":"stdout","text":["Saved new best model with validation loss: 0.2780155837535858\n","Epoch 45 completed, Mean Validation Loss across all episodes: 0.2780155837535858\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"]},{"output_type":"stream","name":"stdout","text":["Saved new best model with validation loss: 0.2735399901866913\n","Epoch 46 completed, Mean Validation Loss across all episodes: 0.2735399901866913\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"]},{"output_type":"stream","name":"stdout","text":["Saved new best model with validation loss: 0.27156561613082886\n","Epoch 47 completed, Mean Validation Loss across all episodes: 0.27156561613082886\n","Epoch 48 completed, Mean Validation Loss across all episodes: 0.27172595262527466\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"]},{"output_type":"stream","name":"stdout","text":["Saved new best model with validation loss: 0.27119654417037964\n","Epoch 49 completed, Mean Validation Loss across all episodes: 0.27119654417037964\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"]},{"output_type":"stream","name":"stdout","text":["Saved new best model with validation loss: 0.2672566771507263\n","Epoch 50 completed, Mean Validation Loss across all episodes: 0.2672566771507263\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"]},{"output_type":"stream","name":"stdout","text":["Saved new best model with validation loss: 0.2641837000846863\n","Epoch 51 completed, Mean Validation Loss across all episodes: 0.2641837000846863\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"]},{"output_type":"stream","name":"stdout","text":["Saved new best model with validation loss: 0.26362118124961853\n","Epoch 52 completed, Mean Validation Loss across all episodes: 0.26362118124961853\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"]},{"output_type":"stream","name":"stdout","text":["Saved new best model with validation loss: 0.26258474588394165\n","Epoch 53 completed, Mean Validation Loss across all episodes: 0.26258474588394165\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"]},{"output_type":"stream","name":"stdout","text":["Saved new best model with validation loss: 0.26001009345054626\n","Epoch 54 completed, Mean Validation Loss across all episodes: 0.26001009345054626\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"]},{"output_type":"stream","name":"stdout","text":["Saved new best model with validation loss: 0.2575299143791199\n","Epoch 55 completed, Mean Validation Loss across all episodes: 0.2575299143791199\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"]},{"output_type":"stream","name":"stdout","text":["Saved new best model with validation loss: 0.25636112689971924\n","Epoch 56 completed, Mean Validation Loss across all episodes: 0.25636112689971924\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"]},{"output_type":"stream","name":"stdout","text":["Saved new best model with validation loss: 0.2560012936592102\n","Epoch 57 completed, Mean Validation Loss across all episodes: 0.2560012936592102\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"]},{"output_type":"stream","name":"stdout","text":["Saved new best model with validation loss: 0.255760133266449\n","Epoch 58 completed, Mean Validation Loss across all episodes: 0.255760133266449\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"]},{"output_type":"stream","name":"stdout","text":["Saved new best model with validation loss: 0.25311988592147827\n","Epoch 59 completed, Mean Validation Loss across all episodes: 0.25311988592147827\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"]},{"output_type":"stream","name":"stdout","text":["Saved new best model with validation loss: 0.25070610642433167\n","Epoch 60 completed, Mean Validation Loss across all episodes: 0.25070610642433167\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"]},{"output_type":"stream","name":"stdout","text":["Saved new best model with validation loss: 0.24800975620746613\n","Epoch 61 completed, Mean Validation Loss across all episodes: 0.24800975620746613\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"]},{"output_type":"stream","name":"stdout","text":["Saved new best model with validation loss: 0.24623259902000427\n","Epoch 62 completed, Mean Validation Loss across all episodes: 0.24623259902000427\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"]},{"output_type":"stream","name":"stdout","text":["Saved new best model with validation loss: 0.24514245986938477\n","Epoch 63 completed, Mean Validation Loss across all episodes: 0.24514245986938477\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"]},{"output_type":"stream","name":"stdout","text":["Saved new best model with validation loss: 0.24478352069854736\n","Epoch 64 completed, Mean Validation Loss across all episodes: 0.24478352069854736\n","Epoch 65 completed, Mean Validation Loss across all episodes: 0.24675822257995605\n","Epoch 66 completed, Mean Validation Loss across all episodes: 0.24690179526805878\n","Epoch 67 completed, Mean Validation Loss across all episodes: 0.24504438042640686\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"]},{"output_type":"stream","name":"stdout","text":["Saved new best model with validation loss: 0.2392890900373459\n","Epoch 68 completed, Mean Validation Loss across all episodes: 0.2392890900373459\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"]},{"output_type":"stream","name":"stdout","text":["Saved new best model with validation loss: 0.2376699000597\n","Epoch 69 completed, Mean Validation Loss across all episodes: 0.2376699000597\n","Epoch 70 completed, Mean Validation Loss across all episodes: 0.23952636122703552\n","Epoch 71 completed, Mean Validation Loss across all episodes: 0.23962163925170898\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"]},{"output_type":"stream","name":"stdout","text":["Saved new best model with validation loss: 0.2366502583026886\n","Epoch 72 completed, Mean Validation Loss across all episodes: 0.2366502583026886\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"]},{"output_type":"stream","name":"stdout","text":["Saved new best model with validation loss: 0.23287372291088104\n","Epoch 73 completed, Mean Validation Loss across all episodes: 0.23287372291088104\n","Epoch 74 completed, Mean Validation Loss across all episodes: 0.2338755577802658\n","Epoch 75 completed, Mean Validation Loss across all episodes: 0.2372680902481079\n","Epoch 76 completed, Mean Validation Loss across all episodes: 0.2348136454820633\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"]},{"output_type":"stream","name":"stdout","text":["Saved new best model with validation loss: 0.22886362671852112\n","Epoch 77 completed, Mean Validation Loss across all episodes: 0.22886362671852112\n","Epoch 78 completed, Mean Validation Loss across all episodes: 0.2347916066646576\n","Epoch 79 completed, Mean Validation Loss across all episodes: 0.23572103679180145\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"]},{"output_type":"stream","name":"stdout","text":["Saved new best model with validation loss: 0.22875580191612244\n","Epoch 80 completed, Mean Validation Loss across all episodes: 0.22875580191612244\n","Epoch 81 completed, Mean Validation Loss across all episodes: 0.2313677817583084\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"]},{"output_type":"stream","name":"stdout","text":["Saved new best model with validation loss: 0.22841370105743408\n","Epoch 82 completed, Mean Validation Loss across all episodes: 0.22841370105743408\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"]},{"output_type":"stream","name":"stdout","text":["Saved new best model with validation loss: 0.22653570771217346\n","Epoch 83 completed, Mean Validation Loss across all episodes: 0.22653570771217346\n","Epoch 84 completed, Mean Validation Loss across all episodes: 0.23161093890666962\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"]},{"output_type":"stream","name":"stdout","text":["Saved new best model with validation loss: 0.22568681836128235\n","Epoch 85 completed, Mean Validation Loss across all episodes: 0.22568681836128235\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"]},{"output_type":"stream","name":"stdout","text":["Saved new best model with validation loss: 0.22444219887256622\n","Epoch 86 completed, Mean Validation Loss across all episodes: 0.22444219887256622\n","Epoch 87 completed, Mean Validation Loss across all episodes: 0.2270773947238922\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"]},{"output_type":"stream","name":"stdout","text":["Saved new best model with validation loss: 0.22182908654212952\n","Epoch 88 completed, Mean Validation Loss across all episodes: 0.22182908654212952\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"]},{"output_type":"stream","name":"stdout","text":["Saved new best model with validation loss: 0.2205473929643631\n","Epoch 89 completed, Mean Validation Loss across all episodes: 0.2205473929643631\n","Epoch 90 completed, Mean Validation Loss across all episodes: 0.22148850560188293\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"]},{"output_type":"stream","name":"stdout","text":["Saved new best model with validation loss: 0.21824367344379425\n","Epoch 91 completed, Mean Validation Loss across all episodes: 0.21824367344379425\n","Epoch 92 completed, Mean Validation Loss across all episodes: 0.2200905829668045\n","Epoch 93 completed, Mean Validation Loss across all episodes: 0.21951131522655487\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"]},{"output_type":"stream","name":"stdout","text":["Saved new best model with validation loss: 0.21562501788139343\n","Epoch 94 completed, Mean Validation Loss across all episodes: 0.21562501788139343\n","Epoch 95 completed, Mean Validation Loss across all episodes: 0.2174651175737381\n","Epoch 96 completed, Mean Validation Loss across all episodes: 0.21698060631752014\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"]},{"output_type":"stream","name":"stdout","text":["Saved new best model with validation loss: 0.21346597373485565\n","Epoch 97 completed, Mean Validation Loss across all episodes: 0.21346597373485565\n","Epoch 98 completed, Mean Validation Loss across all episodes: 0.2143508940935135\n","Epoch 99 completed, Mean Validation Loss across all episodes: 0.21586613357067108\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"]},{"output_type":"stream","name":"stdout","text":["Saved new best model with validation loss: 0.21105608344078064\n","Epoch 100 completed, Mean Validation Loss across all episodes: 0.21105608344078064\n","Epoch 101 completed, Mean Validation Loss across all episodes: 0.21129897236824036\n","Epoch 102 completed, Mean Validation Loss across all episodes: 0.21386435627937317\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"]},{"output_type":"stream","name":"stdout","text":["Saved new best model with validation loss: 0.21104462444782257\n","Epoch 103 completed, Mean Validation Loss across all episodes: 0.21104462444782257\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"]},{"output_type":"stream","name":"stdout","text":["Saved new best model with validation loss: 0.20779645442962646\n","Epoch 104 completed, Mean Validation Loss across all episodes: 0.20779645442962646\n","Epoch 105 completed, Mean Validation Loss across all episodes: 0.2085815966129303\n","Epoch 106 completed, Mean Validation Loss across all episodes: 0.20876696705818176\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"]},{"output_type":"stream","name":"stdout","text":["Saved new best model with validation loss: 0.20778293907642365\n","Epoch 107 completed, Mean Validation Loss across all episodes: 0.20778293907642365\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"]},{"output_type":"stream","name":"stdout","text":["Saved new best model with validation loss: 0.20510800182819366\n","Epoch 108 completed, Mean Validation Loss across all episodes: 0.20510800182819366\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"]},{"output_type":"stream","name":"stdout","text":["Saved new best model with validation loss: 0.20495395362377167\n","Epoch 109 completed, Mean Validation Loss across all episodes: 0.20495395362377167\n","Epoch 110 completed, Mean Validation Loss across all episodes: 0.20558643341064453\n","Epoch 111 completed, Mean Validation Loss across all episodes: 0.2055923044681549\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"]},{"output_type":"stream","name":"stdout","text":["Saved new best model with validation loss: 0.20446249842643738\n","Epoch 112 completed, Mean Validation Loss across all episodes: 0.20446249842643738\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"]},{"output_type":"stream","name":"stdout","text":["Saved new best model with validation loss: 0.20260246098041534\n","Epoch 113 completed, Mean Validation Loss across all episodes: 0.20260246098041534\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"]},{"output_type":"stream","name":"stdout","text":["Saved new best model with validation loss: 0.20104193687438965\n","Epoch 114 completed, Mean Validation Loss across all episodes: 0.20104193687438965\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"]},{"output_type":"stream","name":"stdout","text":["Saved new best model with validation loss: 0.2003001719713211\n","Epoch 115 completed, Mean Validation Loss across all episodes: 0.2003001719713211\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"]},{"output_type":"stream","name":"stdout","text":["Saved new best model with validation loss: 0.19992713630199432\n","Epoch 116 completed, Mean Validation Loss across all episodes: 0.19992713630199432\n","Epoch 117 completed, Mean Validation Loss across all episodes: 0.19998955726623535\n","Epoch 118 completed, Mean Validation Loss across all episodes: 0.20074394345283508\n","Epoch 119 completed, Mean Validation Loss across all episodes: 0.2027205228805542\n","Epoch 120 completed, Mean Validation Loss across all episodes: 0.20427381992340088\n","Epoch 121 completed, Mean Validation Loss across all episodes: 0.20093555748462677\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"]},{"output_type":"stream","name":"stdout","text":["Saved new best model with validation loss: 0.19695548713207245\n","Epoch 122 completed, Mean Validation Loss across all episodes: 0.19695548713207245\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"]},{"output_type":"stream","name":"stdout","text":["Saved new best model with validation loss: 0.19564706087112427\n","Epoch 123 completed, Mean Validation Loss across all episodes: 0.19564706087112427\n","Epoch 124 completed, Mean Validation Loss across all episodes: 0.19689524173736572\n","Epoch 125 completed, Mean Validation Loss across all episodes: 0.1990009993314743\n","Epoch 126 completed, Mean Validation Loss across all episodes: 0.19714152812957764\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"]},{"output_type":"stream","name":"stdout","text":["Saved new best model with validation loss: 0.19457419216632843\n","Epoch 127 completed, Mean Validation Loss across all episodes: 0.19457419216632843\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"]},{"output_type":"stream","name":"stdout","text":["Saved new best model with validation loss: 0.19284473359584808\n","Epoch 128 completed, Mean Validation Loss across all episodes: 0.19284473359584808\n","Epoch 129 completed, Mean Validation Loss across all episodes: 0.19330359995365143\n","Epoch 130 completed, Mean Validation Loss across all episodes: 0.1950249969959259\n","Epoch 131 completed, Mean Validation Loss across all episodes: 0.19546332955360413\n","Epoch 132 completed, Mean Validation Loss across all episodes: 0.19441866874694824\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"]},{"output_type":"stream","name":"stdout","text":["Saved new best model with validation loss: 0.1917916238307953\n","Epoch 133 completed, Mean Validation Loss across all episodes: 0.1917916238307953\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"]},{"output_type":"stream","name":"stdout","text":["Saved new best model with validation loss: 0.19007551670074463\n","Epoch 134 completed, Mean Validation Loss across all episodes: 0.19007551670074463\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"]},{"output_type":"stream","name":"stdout","text":["Saved new best model with validation loss: 0.18909801542758942\n","Epoch 135 completed, Mean Validation Loss across all episodes: 0.18909801542758942\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"]},{"output_type":"stream","name":"stdout","text":["Saved new best model with validation loss: 0.1887800097465515\n","Epoch 136 completed, Mean Validation Loss across all episodes: 0.1887800097465515\n","Epoch 137 completed, Mean Validation Loss across all episodes: 0.18930158019065857\n","Epoch 138 completed, Mean Validation Loss across all episodes: 0.19240231812000275\n","Epoch 139 completed, Mean Validation Loss across all episodes: 0.19896148145198822\n","Epoch 140 completed, Mean Validation Loss across all episodes: 0.19741074740886688\n","Epoch 141 completed, Mean Validation Loss across all episodes: 0.1895127296447754\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"]},{"output_type":"stream","name":"stdout","text":["Saved new best model with validation loss: 0.18596377968788147\n","Epoch 142 completed, Mean Validation Loss across all episodes: 0.18596377968788147\n","Epoch 143 completed, Mean Validation Loss across all episodes: 0.1904224455356598\n","Epoch 144 completed, Mean Validation Loss across all episodes: 0.19447986781597137\n","Epoch 145 completed, Mean Validation Loss across all episodes: 0.18936045467853546\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"]},{"output_type":"stream","name":"stdout","text":["Saved new best model with validation loss: 0.1839856505393982\n","Epoch 146 completed, Mean Validation Loss across all episodes: 0.1839856505393982\n","Epoch 147 completed, Mean Validation Loss across all episodes: 0.1890573501586914\n","Epoch 148 completed, Mean Validation Loss across all episodes: 0.19281251728534698\n","Epoch 149 completed, Mean Validation Loss across all episodes: 0.18725790083408356\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"]},{"output_type":"stream","name":"stdout","text":["Saved new best model with validation loss: 0.1834757775068283\n","Epoch 150 completed, Mean Validation Loss across all episodes: 0.1834757775068283\n","Epoch 151 completed, Mean Validation Loss across all episodes: 0.19248972833156586\n","Epoch 152 completed, Mean Validation Loss across all episodes: 0.1890803873538971\n","Epoch 153 completed, Mean Validation Loss across all episodes: 0.18387146294116974\n","Epoch 154 completed, Mean Validation Loss across all episodes: 0.1841268241405487\n","Epoch 155 completed, Mean Validation Loss across all episodes: 0.18768349289894104\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"]},{"output_type":"stream","name":"stdout","text":["Saved new best model with validation loss: 0.18271894752979279\n","Epoch 156 completed, Mean Validation Loss across all episodes: 0.18271894752979279\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"]},{"output_type":"stream","name":"stdout","text":["Saved new best model with validation loss: 0.180808424949646\n","Epoch 157 completed, Mean Validation Loss across all episodes: 0.180808424949646\n","Epoch 158 completed, Mean Validation Loss across all episodes: 0.1810915172100067\n","Epoch 159 completed, Mean Validation Loss across all episodes: 0.18088987469673157\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"]},{"output_type":"stream","name":"stdout","text":["Saved new best model with validation loss: 0.17903189361095428\n","Epoch 160 completed, Mean Validation Loss across all episodes: 0.17903189361095428\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"]},{"output_type":"stream","name":"stdout","text":["Saved new best model with validation loss: 0.17816786468029022\n","Epoch 161 completed, Mean Validation Loss across all episodes: 0.17816786468029022\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"]},{"output_type":"stream","name":"stdout","text":["Saved new best model with validation loss: 0.17750227451324463\n","Epoch 162 completed, Mean Validation Loss across all episodes: 0.17750227451324463\n","Epoch 163 completed, Mean Validation Loss across all episodes: 0.1779015064239502\n","Epoch 164 completed, Mean Validation Loss across all episodes: 0.1777302324771881\n","Epoch 165 completed, Mean Validation Loss across all episodes: 0.1788996458053589\n","Epoch 166 completed, Mean Validation Loss across all episodes: 0.1782594919204712\n","Epoch 167 completed, Mean Validation Loss across all episodes: 0.17849493026733398\n","Epoch 168 completed, Mean Validation Loss across all episodes: 0.1780681610107422\n","Epoch 169 completed, Mean Validation Loss across all episodes: 0.1778966188430786\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"]},{"output_type":"stream","name":"stdout","text":["Saved new best model with validation loss: 0.17598707973957062\n","Epoch 170 completed, Mean Validation Loss across all episodes: 0.17598707973957062\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"]},{"output_type":"stream","name":"stdout","text":["Saved new best model with validation loss: 0.17504481971263885\n","Epoch 171 completed, Mean Validation Loss across all episodes: 0.17504481971263885\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"]},{"output_type":"stream","name":"stdout","text":["Saved new best model with validation loss: 0.174386665225029\n","Epoch 172 completed, Mean Validation Loss across all episodes: 0.174386665225029\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"]},{"output_type":"stream","name":"stdout","text":["Saved new best model with validation loss: 0.1733415424823761\n","Epoch 173 completed, Mean Validation Loss across all episodes: 0.1733415424823761\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"]},{"output_type":"stream","name":"stdout","text":["Saved new best model with validation loss: 0.17225894331932068\n","Epoch 174 completed, Mean Validation Loss across all episodes: 0.17225894331932068\n","Epoch 175 completed, Mean Validation Loss across all episodes: 0.172311469912529\n","Epoch 176 completed, Mean Validation Loss across all episodes: 0.17545829713344574\n","Epoch 177 completed, Mean Validation Loss across all episodes: 0.18274717032909393\n","Epoch 178 completed, Mean Validation Loss across all episodes: 0.18666215240955353\n","Epoch 179 completed, Mean Validation Loss across all episodes: 0.17679545283317566\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"]},{"output_type":"stream","name":"stdout","text":["Saved new best model with validation loss: 0.17019779980182648\n","Epoch 180 completed, Mean Validation Loss across all episodes: 0.17019779980182648\n","Epoch 181 completed, Mean Validation Loss across all episodes: 0.17554374039173126\n","Epoch 182 completed, Mean Validation Loss across all episodes: 0.18127447366714478\n","Epoch 183 completed, Mean Validation Loss across all episodes: 0.17577557265758514\n","Epoch 184 completed, Mean Validation Loss across all episodes: 0.17023026943206787\n","Epoch 185 completed, Mean Validation Loss across all episodes: 0.18100816011428833\n","Epoch 186 completed, Mean Validation Loss across all episodes: 0.17251701653003693\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"]},{"output_type":"stream","name":"stdout","text":["Saved new best model with validation loss: 0.1696205586194992\n","Epoch 187 completed, Mean Validation Loss across all episodes: 0.1696205586194992\n","Epoch 188 completed, Mean Validation Loss across all episodes: 0.17315752804279327\n","Epoch 189 completed, Mean Validation Loss across all episodes: 0.17115117609500885\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"]},{"output_type":"stream","name":"stdout","text":["Saved new best model with validation loss: 0.166734978556633\n","Epoch 190 completed, Mean Validation Loss across all episodes: 0.166734978556633\n","Epoch 191 completed, Mean Validation Loss across all episodes: 0.16799786686897278\n","Epoch 192 completed, Mean Validation Loss across all episodes: 0.170289546251297\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"]},{"output_type":"stream","name":"stdout","text":["Saved new best model with validation loss: 0.16659432649612427\n","Epoch 193 completed, Mean Validation Loss across all episodes: 0.16659432649612427\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"]},{"output_type":"stream","name":"stdout","text":["Saved new best model with validation loss: 0.16490554809570312\n","Epoch 194 completed, Mean Validation Loss across all episodes: 0.16490554809570312\n","Epoch 195 completed, Mean Validation Loss across all episodes: 0.1654222309589386\n","Epoch 196 completed, Mean Validation Loss across all episodes: 0.16638043522834778\n","Epoch 197 completed, Mean Validation Loss across all episodes: 0.16589495539665222\n"]}],"source":["# Example usage:\n","unet_model = SimpleUNet(input_shape=(224, 224, 8))\n","model = unet_model.build_model()\n","model.summary()\n","\n","# Dynamic LR\n","adapted_model, name = maml_model(model, meta_train_episodes, initial_meta_lr=0.001, initial_inner_lr=0.001, decay_steps=1000, decay_rate=0.96, meta_batch_size=1, inner_steps=1, epochs=500)\n","print(\"model name:\", name)"]},{"cell_type":"markdown","metadata":{"id":"IVRxWtOe1Wrd"},"source":["## 6. Adapt the model to tartget area\n","After we ge the model that is trained on Alexander and Rowancreek using MAML.  "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5LfV4dVh1SIK"},"outputs":[],"source":["def adapt_to_new_task(base_model, support_data, support_labels, inner_lr=0.001, inner_steps=1):\n","    model_copy = tf.keras.models.clone_model(base_model)\n","    model_copy.set_weights(base_model.get_weights())\n","\n","    optimizer = tf.keras.optimizers.Adam(learning_rate=inner_lr)\n","    for i in range(inner_steps):\n","        with tf.GradientTape() as tape:\n","            predictions = model_copy(support_data)\n","            loss = dice_loss(support_labels, predictions)\n","        gradients = tape.gradient(loss, model_copy.trainable_variables)\n","        optimizer.apply_gradients(zip(gradients, model_copy.trainable_variables))\n","        print(f\"Inner Step: {i+1}, Loss: {loss.numpy()}\")\n","    return model_copy\n","\n","def evaluate_adapted_model(model, query_data, query_labels):\n","    predictions = model(query_data)\n","    loss = dice_loss(query_labels, predictions)\n","    return loss.numpy()"]},{"cell_type":"code","source":["locations_meta_testing = ['Covington']\n","# locations_meta_testing = ['Rowancreek']\n","# locations_meta_training = ['Alexander', 'Rowancreek']\n","meta_test_episodes = data_loader.create_multi_episodes(4, locations_meta_testing)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dlz7pvITUWYE","executionInfo":{"status":"ok","timestamp":1714774652435,"user_tz":300,"elapsed":9304,"user":{"displayName":"Nattapon Jaroenchai","userId":"17092454241854925654"}},"outputId":"5278ff13-0bdf-4240-8042-9b3f842ae1d7"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Covington\n","Covington\n","Covington\n","Covington\n"]}]},{"cell_type":"code","source":["name = \"maml_1_500_1_20240503_201907_best_model\"\n","base_model = tf.keras.models.load_model('models/'+name)\n","\n","# Example usage:\n","for test_episode in meta_test_episodes:\n","    adapted_model = adapt_to_new_task(base_model, test_episode[\"support_set_data\"], test_episode[\"support_set_labels\"], inner_lr=0.001, inner_steps=400)\n","    test_loss = evaluate_adapted_model(adapted_model, test_episode[\"query_set_data\"], test_episode[\"query_set_labels\"])\n","    print(f\"Test Loss after adaptation: {test_loss}\")\n","\n","adapted_model.save('models/'+name+'/adapted_covington')  # Save the best model"],"metadata":{"id":"Tc_651su8DZ7","executionInfo":{"status":"ok","timestamp":1714775341556,"user_tz":300,"elapsed":207987,"user":{"displayName":"Nattapon Jaroenchai","userId":"17092454241854925654"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"c7371963-3d7f-41a8-8cab-5ad4a801243b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"]},{"output_type":"stream","name":"stdout","text":["Inner Step: 1, Loss: 0.7070581912994385\n","Inner Step: 2, Loss: 0.6860436201095581\n","Inner Step: 3, Loss: 0.648269772529602\n","Inner Step: 4, Loss: 0.616706132888794\n","Inner Step: 5, Loss: 0.6115401983261108\n","Inner Step: 6, Loss: 0.6031354665756226\n","Inner Step: 7, Loss: 0.588828980922699\n","Inner Step: 8, Loss: 0.576479434967041\n","Inner Step: 9, Loss: 0.5720885992050171\n","Inner Step: 10, Loss: 0.5728148221969604\n","Inner Step: 11, Loss: 0.5644044876098633\n","Inner Step: 12, Loss: 0.555587887763977\n","Inner Step: 13, Loss: 0.5521668195724487\n","Inner Step: 14, Loss: 0.5511040687561035\n","Inner Step: 15, Loss: 0.5485281944274902\n","Inner Step: 16, Loss: 0.5442174077033997\n","Inner Step: 17, Loss: 0.5417673587799072\n","Inner Step: 18, Loss: 0.5420837998390198\n","Inner Step: 19, Loss: 0.5413864850997925\n","Inner Step: 20, Loss: 0.5384175777435303\n","Inner Step: 21, Loss: 0.536340594291687\n","Inner Step: 22, Loss: 0.5360579490661621\n","Inner Step: 23, Loss: 0.5344541072845459\n","Inner Step: 24, Loss: 0.5314226746559143\n","Inner Step: 25, Loss: 0.5293649435043335\n","Inner Step: 26, Loss: 0.5290491580963135\n","Inner Step: 27, Loss: 0.5270063877105713\n","Inner Step: 28, Loss: 0.5238653421401978\n","Inner Step: 29, Loss: 0.5226025581359863\n","Inner Step: 30, Loss: 0.5217782258987427\n","Inner Step: 31, Loss: 0.5194157361984253\n","Inner Step: 32, Loss: 0.5164711475372314\n","Inner Step: 33, Loss: 0.5154104232788086\n","Inner Step: 34, Loss: 0.5141844749450684\n","Inner Step: 35, Loss: 0.5115798711776733\n","Inner Step: 36, Loss: 0.5102100968360901\n","Inner Step: 37, Loss: 0.5086472034454346\n","Inner Step: 38, Loss: 0.5060875415802002\n","Inner Step: 39, Loss: 0.5050272941589355\n","Inner Step: 40, Loss: 0.5037156343460083\n","Inner Step: 41, Loss: 0.5023964643478394\n","Inner Step: 42, Loss: 0.5008390545845032\n","Inner Step: 43, Loss: 0.4986935257911682\n","Inner Step: 44, Loss: 0.4971235394477844\n","Inner Step: 45, Loss: 0.4957551956176758\n","Inner Step: 46, Loss: 0.49409669637680054\n","Inner Step: 47, Loss: 0.49259185791015625\n","Inner Step: 48, Loss: 0.4909449815750122\n","Inner Step: 49, Loss: 0.48937463760375977\n","Inner Step: 50, Loss: 0.48790472745895386\n","Inner Step: 51, Loss: 0.48614412546157837\n","Inner Step: 52, Loss: 0.4845936894416809\n","Inner Step: 53, Loss: 0.4832361340522766\n","Inner Step: 54, Loss: 0.48153430223464966\n","Inner Step: 55, Loss: 0.47995877265930176\n","Inner Step: 56, Loss: 0.47843796014785767\n","Inner Step: 57, Loss: 0.4765166640281677\n","Inner Step: 58, Loss: 0.4742851257324219\n","Inner Step: 59, Loss: 0.47243112325668335\n","Inner Step: 60, Loss: 0.4716034531593323\n","Inner Step: 61, Loss: 0.46942973136901855\n","Inner Step: 62, Loss: 0.46873968839645386\n","Inner Step: 63, Loss: 0.4660387635231018\n","Inner Step: 64, Loss: 0.4642019271850586\n","Inner Step: 65, Loss: 0.4621008038520813\n","Inner Step: 66, Loss: 0.4605674147605896\n","Inner Step: 67, Loss: 0.4590381979942322\n","Inner Step: 68, Loss: 0.4572441577911377\n","Inner Step: 69, Loss: 0.4557012915611267\n","Inner Step: 70, Loss: 0.4548603892326355\n","Inner Step: 71, Loss: 0.45811766386032104\n","Inner Step: 72, Loss: 0.4634438157081604\n","Inner Step: 73, Loss: 0.45774906873703003\n","Inner Step: 74, Loss: 0.45016539096832275\n","Inner Step: 75, Loss: 0.46096909046173096\n","Inner Step: 76, Loss: 0.4507639408111572\n","Inner Step: 77, Loss: 0.45074528455734253\n","Inner Step: 78, Loss: 0.45356202125549316\n","Inner Step: 79, Loss: 0.4450434446334839\n","Inner Step: 80, Loss: 0.45451509952545166\n","Inner Step: 81, Loss: 0.44254070520401\n","Inner Step: 82, Loss: 0.44995206594467163\n","Inner Step: 83, Loss: 0.4436022639274597\n","Inner Step: 84, Loss: 0.44133687019348145\n","Inner Step: 85, Loss: 0.444594144821167\n","Inner Step: 86, Loss: 0.4374197721481323\n","Inner Step: 87, Loss: 0.4417634606361389\n","Inner Step: 88, Loss: 0.43809449672698975\n","Inner Step: 89, Loss: 0.43645989894866943\n","Inner Step: 90, Loss: 0.437821626663208\n","Inner Step: 91, Loss: 0.43251627683639526\n","Inner Step: 92, Loss: 0.4354501962661743\n","Inner Step: 93, Loss: 0.43427079916000366\n","Inner Step: 94, Loss: 0.42911040782928467\n","Inner Step: 95, Loss: 0.4310636520385742\n","Inner Step: 96, Loss: 0.42909538745880127\n","Inner Step: 97, Loss: 0.4263477325439453\n","Inner Step: 98, Loss: 0.427163302898407\n","Inner Step: 99, Loss: 0.42759209871292114\n","Inner Step: 100, Loss: 0.4244212508201599\n","Inner Step: 101, Loss: 0.4218965172767639\n","Inner Step: 102, Loss: 0.42148393392562866\n","Inner Step: 103, Loss: 0.4221898317337036\n","Inner Step: 104, Loss: 0.4228575825691223\n","Inner Step: 105, Loss: 0.42179977893829346\n","Inner Step: 106, Loss: 0.42024195194244385\n","Inner Step: 107, Loss: 0.41681694984436035\n","Inner Step: 108, Loss: 0.41453272104263306\n","Inner Step: 109, Loss: 0.4141530990600586\n","Inner Step: 110, Loss: 0.41481447219848633\n","Inner Step: 111, Loss: 0.4172273874282837\n","Inner Step: 112, Loss: 0.42084789276123047\n","Inner Step: 113, Loss: 0.4236789345741272\n","Inner Step: 114, Loss: 0.40968483686447144\n","Inner Step: 115, Loss: 0.4162139296531677\n","Inner Step: 116, Loss: 0.42576032876968384\n","Inner Step: 117, Loss: 0.4069799780845642\n","Inner Step: 118, Loss: 0.42342692613601685\n","Inner Step: 119, Loss: 0.43390899896621704\n","Inner Step: 120, Loss: 0.41802680492401123\n","Inner Step: 121, Loss: 0.44174617528915405\n","Inner Step: 122, Loss: 0.4057821035385132\n","Inner Step: 123, Loss: 0.4248799681663513\n","Inner Step: 124, Loss: 0.40522241592407227\n","Inner Step: 125, Loss: 0.4245483875274658\n","Inner Step: 126, Loss: 0.404247522354126\n","Inner Step: 127, Loss: 0.4159232974052429\n","Inner Step: 128, Loss: 0.40191650390625\n","Inner Step: 129, Loss: 0.4114370346069336\n","Inner Step: 130, Loss: 0.4038018584251404\n","Inner Step: 131, Loss: 0.4051896929740906\n","Inner Step: 132, Loss: 0.40287458896636963\n","Inner Step: 133, Loss: 0.4017619490623474\n","Inner Step: 134, Loss: 0.40274155139923096\n","Inner Step: 135, Loss: 0.3980864882469177\n","Inner Step: 136, Loss: 0.4023335576057434\n","Inner Step: 137, Loss: 0.39578908681869507\n","Inner Step: 138, Loss: 0.397491455078125\n","Inner Step: 139, Loss: 0.3954864740371704\n","Inner Step: 140, Loss: 0.39482682943344116\n","Inner Step: 141, Loss: 0.3949200510978699\n","Inner Step: 142, Loss: 0.3920605778694153\n","Inner Step: 143, Loss: 0.3938080072402954\n","Inner Step: 144, Loss: 0.39184820652008057\n","Inner Step: 145, Loss: 0.39027172327041626\n","Inner Step: 146, Loss: 0.39102596044540405\n","Inner Step: 147, Loss: 0.3891488313674927\n","Inner Step: 148, Loss: 0.3879774808883667\n","Inner Step: 149, Loss: 0.3889249563217163\n","Inner Step: 150, Loss: 0.38705796003341675\n","Inner Step: 151, Loss: 0.3856234550476074\n","Inner Step: 152, Loss: 0.38547343015670776\n","Inner Step: 153, Loss: 0.385850727558136\n","Inner Step: 154, Loss: 0.38494157791137695\n","Inner Step: 155, Loss: 0.38267940282821655\n","Inner Step: 156, Loss: 0.3821239471435547\n","Inner Step: 157, Loss: 0.3827887177467346\n","Inner Step: 158, Loss: 0.38374513387680054\n","Inner Step: 159, Loss: 0.3842208981513977\n","Inner Step: 160, Loss: 0.3832549452781677\n","Inner Step: 161, Loss: 0.37982940673828125\n","Inner Step: 162, Loss: 0.37792694568634033\n","Inner Step: 163, Loss: 0.377172589302063\n","Inner Step: 164, Loss: 0.37746137380599976\n","Inner Step: 165, Loss: 0.37959975004196167\n","Inner Step: 166, Loss: 0.3841036558151245\n","Inner Step: 167, Loss: 0.3921964764595032\n","Inner Step: 168, Loss: 0.37671422958374023\n","Inner Step: 169, Loss: 0.37580549716949463\n","Inner Step: 170, Loss: 0.387287974357605\n","Inner Step: 171, Loss: 0.3821803331375122\n","Inner Step: 172, Loss: 0.37858492136001587\n","Inner Step: 173, Loss: 0.37203168869018555\n","Inner Step: 174, Loss: 0.37653952836990356\n","Inner Step: 175, Loss: 0.38670432567596436\n","Inner Step: 176, Loss: 0.37835752964019775\n","Inner Step: 177, Loss: 0.3723794221878052\n","Inner Step: 178, Loss: 0.3735656142234802\n","Inner Step: 179, Loss: 0.3741576075553894\n","Inner Step: 180, Loss: 0.3708546757698059\n","Inner Step: 181, Loss: 0.36826491355895996\n","Inner Step: 182, Loss: 0.370577335357666\n","Inner Step: 183, Loss: 0.3711165189743042\n","Inner Step: 184, Loss: 0.36758953332901\n","Inner Step: 185, Loss: 0.36658716201782227\n","Inner Step: 186, Loss: 0.3669434189796448\n","Inner Step: 187, Loss: 0.36848366260528564\n","Inner Step: 188, Loss: 0.3679289221763611\n","Inner Step: 189, Loss: 0.3642526865005493\n","Inner Step: 190, Loss: 0.36295026540756226\n","Inner Step: 191, Loss: 0.36282879114151\n","Inner Step: 192, Loss: 0.3638584017753601\n","Inner Step: 193, Loss: 0.36356526613235474\n","Inner Step: 194, Loss: 0.36066120862960815\n","Inner Step: 195, Loss: 0.35970938205718994\n","Inner Step: 196, Loss: 0.35903578996658325\n","Inner Step: 197, Loss: 0.36027365922927856\n","Inner Step: 198, Loss: 0.3631232976913452\n","Inner Step: 199, Loss: 0.36710673570632935\n","Inner Step: 200, Loss: 0.3729690909385681\n","Inner Step: 201, Loss: 0.36677318811416626\n","Inner Step: 202, Loss: 0.3599509596824646\n","Inner Step: 203, Loss: 0.3554147481918335\n","Inner Step: 204, Loss: 0.36019039154052734\n","Inner Step: 205, Loss: 0.3722754120826721\n","Inner Step: 206, Loss: 0.372089684009552\n","Inner Step: 207, Loss: 0.36367785930633545\n","Inner Step: 208, Loss: 0.35633182525634766\n","Inner Step: 209, Loss: 0.36701059341430664\n","Inner Step: 210, Loss: 0.366726279258728\n","Inner Step: 211, Loss: 0.3524259328842163\n","Inner Step: 212, Loss: 0.36357802152633667\n","Inner Step: 213, Loss: 0.3729620575904846\n","Inner Step: 214, Loss: 0.3512476086616516\n","Inner Step: 215, Loss: 0.36908918619155884\n","Inner Step: 216, Loss: 0.3732050061225891\n","Inner Step: 217, Loss: 0.35172587633132935\n","Inner Step: 218, Loss: 0.3719135522842407\n","Inner Step: 219, Loss: 0.3623002767562866\n","Inner Step: 220, Loss: 0.35446399450302124\n","Inner Step: 221, Loss: 0.3731599450111389\n","Inner Step: 222, Loss: 0.35293447971343994\n","Inner Step: 223, Loss: 0.35514354705810547\n","Inner Step: 224, Loss: 0.3595515489578247\n","Inner Step: 225, Loss: 0.3487745523452759\n","Inner Step: 226, Loss: 0.3560575246810913\n","Inner Step: 227, Loss: 0.3474777936935425\n","Inner Step: 228, Loss: 0.3507818579673767\n","Inner Step: 229, Loss: 0.35297560691833496\n","Inner Step: 230, Loss: 0.3451000452041626\n","Inner Step: 231, Loss: 0.3506356477737427\n","Inner Step: 232, Loss: 0.34623420238494873\n","Inner Step: 233, Loss: 0.3458019495010376\n","Inner Step: 234, Loss: 0.34736788272857666\n","Inner Step: 235, Loss: 0.3419365882873535\n","Inner Step: 236, Loss: 0.3452393412590027\n","Inner Step: 237, Loss: 0.344191312789917\n","Inner Step: 238, Loss: 0.34047985076904297\n","Inner Step: 239, Loss: 0.3422543406486511\n","Inner Step: 240, Loss: 0.3419237732887268\n","Inner Step: 241, Loss: 0.3393927216529846\n","Inner Step: 242, Loss: 0.340157687664032\n","Inner Step: 243, Loss: 0.3403025269508362\n","Inner Step: 244, Loss: 0.33807438611984253\n","Inner Step: 245, Loss: 0.3370409607887268\n","Inner Step: 246, Loss: 0.33812886476516724\n","Inner Step: 247, Loss: 0.33819764852523804\n","Inner Step: 248, Loss: 0.3363964557647705\n","Inner Step: 249, Loss: 0.3350808620452881\n","Inner Step: 250, Loss: 0.33455580472946167\n","Inner Step: 251, Loss: 0.3349927067756653\n","Inner Step: 252, Loss: 0.335548460483551\n","Inner Step: 253, Loss: 0.3351317048072815\n","Inner Step: 254, Loss: 0.3350456953048706\n","Inner Step: 255, Loss: 0.33412599563598633\n","Inner Step: 256, Loss: 0.3334499001502991\n","Inner Step: 257, Loss: 0.3320288062095642\n","Inner Step: 258, Loss: 0.33096110820770264\n","Inner Step: 259, Loss: 0.3299708962440491\n","Inner Step: 260, Loss: 0.3295156955718994\n","Inner Step: 261, Loss: 0.3293367624282837\n","Inner Step: 262, Loss: 0.32961881160736084\n","Inner Step: 263, Loss: 0.33087462186813354\n","Inner Step: 264, Loss: 0.334133505821228\n","Inner Step: 265, Loss: 0.34463202953338623\n","Inner Step: 266, Loss: 0.3437195420265198\n","Inner Step: 267, Loss: 0.3426975607872009\n","Inner Step: 268, Loss: 0.3292614817619324\n","Inner Step: 269, Loss: 0.3281667232513428\n","Inner Step: 270, Loss: 0.33716094493865967\n","Inner Step: 271, Loss: 0.33518344163894653\n","Inner Step: 272, Loss: 0.32965904474258423\n","Inner Step: 273, Loss: 0.32547998428344727\n","Inner Step: 274, Loss: 0.3311500549316406\n","Inner Step: 275, Loss: 0.33647024631500244\n","Inner Step: 276, Loss: 0.32856285572052\n","Inner Step: 277, Loss: 0.32431888580322266\n","Inner Step: 278, Loss: 0.3274649977684021\n","Inner Step: 279, Loss: 0.32629990577697754\n","Inner Step: 280, Loss: 0.3233188986778259\n","Inner Step: 281, Loss: 0.32249051332473755\n","Inner Step: 282, Loss: 0.32349693775177\n","Inner Step: 283, Loss: 0.3259470462799072\n","Inner Step: 284, Loss: 0.3235071897506714\n","Inner Step: 285, Loss: 0.3211911916732788\n","Inner Step: 286, Loss: 0.31995195150375366\n","Inner Step: 287, Loss: 0.32070493698120117\n","Inner Step: 288, Loss: 0.3226720690727234\n","Inner Step: 289, Loss: 0.3246381878852844\n","Inner Step: 290, Loss: 0.3272239565849304\n","Inner Step: 291, Loss: 0.3212168216705322\n","Inner Step: 292, Loss: 0.31793302297592163\n","Inner Step: 293, Loss: 0.31759828329086304\n","Inner Step: 294, Loss: 0.3199402093887329\n","Inner Step: 295, Loss: 0.32535868883132935\n","Inner Step: 296, Loss: 0.3254040479660034\n","Inner Step: 297, Loss: 0.3267056941986084\n","Inner Step: 298, Loss: 0.3185945749282837\n","Inner Step: 299, Loss: 0.31522244215011597\n","Inner Step: 300, Loss: 0.3191758990287781\n","Inner Step: 301, Loss: 0.32247936725616455\n","Inner Step: 302, Loss: 0.32854676246643066\n","Inner Step: 303, Loss: 0.32039082050323486\n","Inner Step: 304, Loss: 0.3144036531448364\n","Inner Step: 305, Loss: 0.3161131739616394\n","Inner Step: 306, Loss: 0.3191312551498413\n","Inner Step: 307, Loss: 0.3219979405403137\n","Inner Step: 308, Loss: 0.31506478786468506\n","Inner Step: 309, Loss: 0.31250762939453125\n","Inner Step: 310, Loss: 0.31611835956573486\n","Inner Step: 311, Loss: 0.31381523609161377\n","Inner Step: 312, Loss: 0.3110803961753845\n","Inner Step: 313, Loss: 0.31041115522384644\n","Inner Step: 314, Loss: 0.31200742721557617\n","Inner Step: 315, Loss: 0.3149506449699402\n","Inner Step: 316, Loss: 0.3121759295463562\n","Inner Step: 317, Loss: 0.31057947874069214\n","Inner Step: 318, Loss: 0.308385968208313\n","Inner Step: 319, Loss: 0.3103460669517517\n","Inner Step: 320, Loss: 0.316001832485199\n","Inner Step: 321, Loss: 0.31973278522491455\n","Inner Step: 322, Loss: 0.3294675350189209\n","Inner Step: 323, Loss: 0.31474268436431885\n","Inner Step: 324, Loss: 0.30750489234924316\n","Inner Step: 325, Loss: 0.31055474281311035\n","Inner Step: 326, Loss: 0.31233441829681396\n","Inner Step: 327, Loss: 0.31469565629959106\n","Inner Step: 328, Loss: 0.30707287788391113\n","Inner Step: 329, Loss: 0.3067576289176941\n","Inner Step: 330, Loss: 0.31390154361724854\n","Inner Step: 331, Loss: 0.3120434284210205\n","Inner Step: 332, Loss: 0.30787885189056396\n","Inner Step: 333, Loss: 0.3050580620765686\n","Inner Step: 334, Loss: 0.3120633363723755\n","Inner Step: 335, Loss: 0.32165348529815674\n","Inner Step: 336, Loss: 0.31703537702560425\n","Inner Step: 337, Loss: 0.30766987800598145\n","Inner Step: 338, Loss: 0.30554062128067017\n","Inner Step: 339, Loss: 0.3145754933357239\n","Inner Step: 340, Loss: 0.31741636991500854\n","Inner Step: 341, Loss: 0.3079181909561157\n","Inner Step: 342, Loss: 0.3042052984237671\n","Inner Step: 343, Loss: 0.3074055314064026\n","Inner Step: 344, Loss: 0.30311864614486694\n","Inner Step: 345, Loss: 0.3022698760032654\n","Inner Step: 346, Loss: 0.3056138753890991\n","Inner Step: 347, Loss: 0.3014146685600281\n","Inner Step: 348, Loss: 0.2993396520614624\n","Inner Step: 349, Loss: 0.302107572555542\n","Inner Step: 350, Loss: 0.301628053188324\n","Inner Step: 351, Loss: 0.30064868927001953\n","Inner Step: 352, Loss: 0.29817551374435425\n","Inner Step: 353, Loss: 0.299437940120697\n","Inner Step: 354, Loss: 0.3045174479484558\n","Inner Step: 355, Loss: 0.3073112368583679\n","Inner Step: 356, Loss: 0.31235694885253906\n","Inner Step: 357, Loss: 0.2995387315750122\n","Inner Step: 358, Loss: 0.2985001802444458\n","Inner Step: 359, Loss: 0.30913645029067993\n","Inner Step: 360, Loss: 0.3083319664001465\n","Inner Step: 361, Loss: 0.30873245000839233\n","Inner Step: 362, Loss: 0.29686588048934937\n","Inner Step: 363, Loss: 0.3053605556488037\n","Inner Step: 364, Loss: 0.32185208797454834\n","Inner Step: 365, Loss: 0.30473023653030396\n","Inner Step: 366, Loss: 0.2965594530105591\n","Inner Step: 367, Loss: 0.30216431617736816\n","Inner Step: 368, Loss: 0.29627615213394165\n","Inner Step: 369, Loss: 0.2951963543891907\n","Inner Step: 370, Loss: 0.3011687994003296\n","Inner Step: 371, Loss: 0.2993566393852234\n","Inner Step: 372, Loss: 0.2947573661804199\n","Inner Step: 373, Loss: 0.2937541604042053\n","Inner Step: 374, Loss: 0.29836219549179077\n","Inner Step: 375, Loss: 0.2978198528289795\n","Inner Step: 376, Loss: 0.2929396629333496\n","Inner Step: 377, Loss: 0.29452675580978394\n","Inner Step: 378, Loss: 0.2990455627441406\n","Inner Step: 379, Loss: 0.29590076208114624\n","Inner Step: 380, Loss: 0.290591835975647\n","Inner Step: 381, Loss: 0.29090893268585205\n","Inner Step: 382, Loss: 0.29348552227020264\n","Inner Step: 383, Loss: 0.2935842275619507\n","Inner Step: 384, Loss: 0.2892451882362366\n","Inner Step: 385, Loss: 0.2885271906852722\n","Inner Step: 386, Loss: 0.2905864119529724\n","Inner Step: 387, Loss: 0.291049063205719\n","Inner Step: 388, Loss: 0.2923647165298462\n","Inner Step: 389, Loss: 0.2890927195549011\n","Inner Step: 390, Loss: 0.2868175506591797\n","Inner Step: 391, Loss: 0.2861677408218384\n","Inner Step: 392, Loss: 0.28702765703201294\n","Inner Step: 393, Loss: 0.2892197370529175\n","Inner Step: 394, Loss: 0.290366530418396\n","Inner Step: 395, Loss: 0.2967045307159424\n","Inner Step: 396, Loss: 0.29899996519088745\n","Inner Step: 397, Loss: 0.303993821144104\n","Inner Step: 398, Loss: 0.28981566429138184\n","Inner Step: 399, Loss: 0.2860754728317261\n","Inner Step: 400, Loss: 0.29490602016448975\n","Test Loss after adaptation: 0.57032310962677\n","Inner Step: 1, Loss: 0.687929093837738\n","Inner Step: 2, Loss: 0.6417914628982544\n","Inner Step: 3, Loss: 0.6055487394332886\n","Inner Step: 4, Loss: 0.5703266859054565\n","Inner Step: 5, Loss: 0.5568329095840454\n","Inner Step: 6, Loss: 0.5438287258148193\n","Inner Step: 7, Loss: 0.5286296606063843\n","Inner Step: 8, Loss: 0.5179070234298706\n","Inner Step: 9, Loss: 0.5134555101394653\n","Inner Step: 10, Loss: 0.5092076659202576\n","Inner Step: 11, Loss: 0.5024649500846863\n","Inner Step: 12, Loss: 0.4963521361351013\n","Inner Step: 13, Loss: 0.493041455745697\n","Inner Step: 14, Loss: 0.4898756146430969\n","Inner Step: 15, Loss: 0.48776543140411377\n","Inner Step: 16, Loss: 0.484469473361969\n","Inner Step: 17, Loss: 0.4812890887260437\n","Inner Step: 18, Loss: 0.4789121150970459\n","Inner Step: 19, Loss: 0.47754281759262085\n","Inner Step: 20, Loss: 0.47474145889282227\n","Inner Step: 21, Loss: 0.4713327884674072\n","Inner Step: 22, Loss: 0.4694429636001587\n","Inner Step: 23, Loss: 0.4665755033493042\n","Inner Step: 24, Loss: 0.4633212089538574\n","Inner Step: 25, Loss: 0.46119213104248047\n","Inner Step: 26, Loss: 0.45809757709503174\n","Inner Step: 27, Loss: 0.4556882381439209\n","Inner Step: 28, Loss: 0.45298266410827637\n","Inner Step: 29, Loss: 0.4504309296607971\n","Inner Step: 30, Loss: 0.4485280513763428\n","Inner Step: 31, Loss: 0.44647538661956787\n","Inner Step: 32, Loss: 0.44427651166915894\n","Inner Step: 33, Loss: 0.4426076412200928\n","Inner Step: 34, Loss: 0.4399293065071106\n","Inner Step: 35, Loss: 0.4383893609046936\n","Inner Step: 36, Loss: 0.4356691837310791\n","Inner Step: 37, Loss: 0.4341217875480652\n","Inner Step: 38, Loss: 0.431499183177948\n","Inner Step: 39, Loss: 0.43031489849090576\n","Inner Step: 40, Loss: 0.4278925657272339\n","Inner Step: 41, Loss: 0.42596322298049927\n","Inner Step: 42, Loss: 0.42432135343551636\n","Inner Step: 43, Loss: 0.42199528217315674\n","Inner Step: 44, Loss: 0.42010366916656494\n","Inner Step: 45, Loss: 0.4179544448852539\n","Inner Step: 46, Loss: 0.4159278869628906\n","Inner Step: 47, Loss: 0.41377758979797363\n","Inner Step: 48, Loss: 0.4114866256713867\n","Inner Step: 49, Loss: 0.4093018174171448\n","Inner Step: 50, Loss: 0.40711385011672974\n","Inner Step: 51, Loss: 0.40469831228256226\n","Inner Step: 52, Loss: 0.4023509621620178\n","Inner Step: 53, Loss: 0.40076756477355957\n","Inner Step: 54, Loss: 0.40384823083877563\n","Inner Step: 55, Loss: 0.4102433919906616\n","Inner Step: 56, Loss: 0.4024943709373474\n","Inner Step: 57, Loss: 0.39821183681488037\n","Inner Step: 58, Loss: 0.40265142917633057\n","Inner Step: 59, Loss: 0.3928806781768799\n","Inner Step: 60, Loss: 0.39941340684890747\n","Inner Step: 61, Loss: 0.3907708525657654\n","Inner Step: 62, Loss: 0.39900338649749756\n","Inner Step: 63, Loss: 0.38707035779953003\n","Inner Step: 64, Loss: 0.3965184688568115\n","Inner Step: 65, Loss: 0.38493478298187256\n","Inner Step: 66, Loss: 0.3923271894454956\n","Inner Step: 67, Loss: 0.3828139901161194\n","Inner Step: 68, Loss: 0.3890313506126404\n","Inner Step: 69, Loss: 0.3820217251777649\n","Inner Step: 70, Loss: 0.38456374406814575\n","Inner Step: 71, Loss: 0.3801878094673157\n","Inner Step: 72, Loss: 0.3807244896888733\n","Inner Step: 73, Loss: 0.3789685368537903\n","Inner Step: 74, Loss: 0.37860506772994995\n","Inner Step: 75, Loss: 0.3771480917930603\n","Inner Step: 76, Loss: 0.37500709295272827\n","Inner Step: 77, Loss: 0.3750438690185547\n","Inner Step: 78, Loss: 0.3726946711540222\n","Inner Step: 79, Loss: 0.3729126453399658\n","Inner Step: 80, Loss: 0.3698495626449585\n","Inner Step: 81, Loss: 0.370855450630188\n","Inner Step: 82, Loss: 0.3682587146759033\n","Inner Step: 83, Loss: 0.36814361810684204\n","Inner Step: 84, Loss: 0.3665817379951477\n","Inner Step: 85, Loss: 0.36461806297302246\n","Inner Step: 86, Loss: 0.3645475506782532\n","Inner Step: 87, Loss: 0.3633333444595337\n","Inner Step: 88, Loss: 0.36156725883483887\n","Inner Step: 89, Loss: 0.36055195331573486\n","Inner Step: 90, Loss: 0.36021941900253296\n","Inner Step: 91, Loss: 0.3595333695411682\n","Inner Step: 92, Loss: 0.35859519243240356\n","Inner Step: 93, Loss: 0.3569697141647339\n","Inner Step: 94, Loss: 0.35553067922592163\n","Inner Step: 95, Loss: 0.35422706604003906\n","Inner Step: 96, Loss: 0.3530716896057129\n","Inner Step: 97, Loss: 0.35217076539993286\n","Inner Step: 98, Loss: 0.35203492641448975\n","Inner Step: 99, Loss: 0.35531526803970337\n","Inner Step: 100, Loss: 0.36903083324432373\n","Inner Step: 101, Loss: 0.3520650863647461\n","Inner Step: 102, Loss: 0.3478621244430542\n","Inner Step: 103, Loss: 0.3517656922340393\n","Inner Step: 104, Loss: 0.3536500334739685\n","Inner Step: 105, Loss: 0.35579270124435425\n","Inner Step: 106, Loss: 0.3441649079322815\n","Inner Step: 107, Loss: 0.34923607110977173\n","Inner Step: 108, Loss: 0.3603469729423523\n","Inner Step: 109, Loss: 0.3418290615081787\n","Inner Step: 110, Loss: 0.36242300271987915\n","Inner Step: 111, Loss: 0.36311960220336914\n","Inner Step: 112, Loss: 0.35120081901550293\n","Inner Step: 113, Loss: 0.3692563772201538\n","Inner Step: 114, Loss: 0.34075915813446045\n","Inner Step: 115, Loss: 0.35861659049987793\n","Inner Step: 116, Loss: 0.3402121663093567\n","Inner Step: 117, Loss: 0.3609292507171631\n","Inner Step: 118, Loss: 0.337310254573822\n","Inner Step: 119, Loss: 0.35147666931152344\n","Inner Step: 120, Loss: 0.3353482484817505\n","Inner Step: 121, Loss: 0.3484033942222595\n","Inner Step: 122, Loss: 0.3370159864425659\n","Inner Step: 123, Loss: 0.33950453996658325\n","Inner Step: 124, Loss: 0.33584171533584595\n","Inner Step: 125, Loss: 0.3332017660140991\n","Inner Step: 126, Loss: 0.3346545696258545\n","Inner Step: 127, Loss: 0.3297090530395508\n","Inner Step: 128, Loss: 0.33341753482818604\n","Inner Step: 129, Loss: 0.3287748694419861\n","Inner Step: 130, Loss: 0.32964468002319336\n","Inner Step: 131, Loss: 0.3290398120880127\n","Inner Step: 132, Loss: 0.32587945461273193\n","Inner Step: 133, Loss: 0.3274593949317932\n","Inner Step: 134, Loss: 0.3250439167022705\n","Inner Step: 135, Loss: 0.3239811658859253\n","Inner Step: 136, Loss: 0.32426440715789795\n","Inner Step: 137, Loss: 0.32168054580688477\n","Inner Step: 138, Loss: 0.3218204975128174\n","Inner Step: 139, Loss: 0.3221118450164795\n","Inner Step: 140, Loss: 0.319515585899353\n","Inner Step: 141, Loss: 0.31912392377853394\n","Inner Step: 142, Loss: 0.3195570111274719\n","Inner Step: 143, Loss: 0.31757962703704834\n","Inner Step: 144, Loss: 0.31619691848754883\n","Inner Step: 145, Loss: 0.31557875871658325\n","Inner Step: 146, Loss: 0.31553733348846436\n","Inner Step: 147, Loss: 0.3162250518798828\n","Inner Step: 148, Loss: 0.31546783447265625\n","Inner Step: 149, Loss: 0.31660354137420654\n","Inner Step: 150, Loss: 0.315265953540802\n","Inner Step: 151, Loss: 0.31592637300491333\n","Inner Step: 152, Loss: 0.3133937120437622\n","Inner Step: 153, Loss: 0.3116210103034973\n","Inner Step: 154, Loss: 0.3092496991157532\n","Inner Step: 155, Loss: 0.30793386697769165\n","Inner Step: 156, Loss: 0.30717360973358154\n","Inner Step: 157, Loss: 0.3066691756248474\n","Inner Step: 158, Loss: 0.3067554831504822\n","Inner Step: 159, Loss: 0.3089866042137146\n","Inner Step: 160, Loss: 0.317599892616272\n","Inner Step: 161, Loss: 0.3151245713233948\n","Inner Step: 162, Loss: 0.3116980791091919\n","Inner Step: 163, Loss: 0.30424362421035767\n","Inner Step: 164, Loss: 0.3043680787086487\n","Inner Step: 165, Loss: 0.3110871911048889\n","Inner Step: 166, Loss: 0.3103047013282776\n","Inner Step: 167, Loss: 0.3075106143951416\n","Inner Step: 168, Loss: 0.30075132846832275\n","Inner Step: 169, Loss: 0.3010298013687134\n","Inner Step: 170, Loss: 0.30538737773895264\n","Inner Step: 171, Loss: 0.30282360315322876\n","Inner Step: 172, Loss: 0.3000146746635437\n","Inner Step: 173, Loss: 0.2972152829170227\n","Inner Step: 174, Loss: 0.29889917373657227\n","Inner Step: 175, Loss: 0.30625051259994507\n","Inner Step: 176, Loss: 0.30284184217453003\n","Inner Step: 177, Loss: 0.3000156283378601\n","Inner Step: 178, Loss: 0.2951841950416565\n","Inner Step: 179, Loss: 0.29612070322036743\n","Inner Step: 180, Loss: 0.3001415729522705\n","Inner Step: 181, Loss: 0.29650580883026123\n","Inner Step: 182, Loss: 0.2937192916870117\n","Inner Step: 183, Loss: 0.29189348220825195\n","Inner Step: 184, Loss: 0.29361480474472046\n","Inner Step: 185, Loss: 0.2986503839492798\n","Inner Step: 186, Loss: 0.2969157099723816\n","Inner Step: 187, Loss: 0.29672491550445557\n","Inner Step: 188, Loss: 0.29063278436660767\n","Inner Step: 189, Loss: 0.2895110249519348\n","Inner Step: 190, Loss: 0.2926219701766968\n","Inner Step: 191, Loss: 0.29162484407424927\n","Inner Step: 192, Loss: 0.29189497232437134\n","Inner Step: 193, Loss: 0.28772783279418945\n","Inner Step: 194, Loss: 0.28690606355667114\n","Inner Step: 195, Loss: 0.28862762451171875\n","Inner Step: 196, Loss: 0.28788477182388306\n","Inner Step: 197, Loss: 0.28883010149002075\n","Inner Step: 198, Loss: 0.2858962416648865\n","Inner Step: 199, Loss: 0.2846267819404602\n","Inner Step: 200, Loss: 0.2832827568054199\n","Inner Step: 201, Loss: 0.2828633785247803\n","Inner Step: 202, Loss: 0.2831761837005615\n","Inner Step: 203, Loss: 0.28435397148132324\n","Inner Step: 204, Loss: 0.2908921241760254\n","Inner Step: 205, Loss: 0.29862236976623535\n","Inner Step: 206, Loss: 0.3096815347671509\n","Inner Step: 207, Loss: 0.2841475009918213\n","Inner Step: 208, Loss: 0.2871224284172058\n","Inner Step: 209, Loss: 0.30191707611083984\n","Inner Step: 210, Loss: 0.2848151922225952\n","Inner Step: 211, Loss: 0.27872234582901\n","Inner Step: 212, Loss: 0.28514301776885986\n","Inner Step: 213, Loss: 0.2871864438056946\n","Inner Step: 214, Loss: 0.2901848554611206\n","Inner Step: 215, Loss: 0.27905547618865967\n","Inner Step: 216, Loss: 0.2796352505683899\n","Inner Step: 217, Loss: 0.2865564227104187\n","Inner Step: 218, Loss: 0.27798813581466675\n","Inner Step: 219, Loss: 0.27593785524368286\n","Inner Step: 220, Loss: 0.2800401449203491\n","Inner Step: 221, Loss: 0.27828139066696167\n","Inner Step: 222, Loss: 0.2758817672729492\n","Inner Step: 223, Loss: 0.27387112379074097\n","Inner Step: 224, Loss: 0.275623619556427\n","Inner Step: 225, Loss: 0.27776414155960083\n","Inner Step: 226, Loss: 0.27310121059417725\n","Inner Step: 227, Loss: 0.27178049087524414\n","Inner Step: 228, Loss: 0.2735168933868408\n","Inner Step: 229, Loss: 0.27428138256073\n","Inner Step: 230, Loss: 0.27764397859573364\n","Inner Step: 231, Loss: 0.27398890256881714\n","Inner Step: 232, Loss: 0.2716485857963562\n","Inner Step: 233, Loss: 0.26888543367385864\n","Inner Step: 234, Loss: 0.27091068029403687\n","Inner Step: 235, Loss: 0.28037071228027344\n","Inner Step: 236, Loss: 0.2824671268463135\n","Inner Step: 237, Loss: 0.2914525866508484\n","Inner Step: 238, Loss: 0.271236777305603\n","Inner Step: 239, Loss: 0.27309417724609375\n","Inner Step: 240, Loss: 0.2926051616668701\n","Inner Step: 241, Loss: 0.27221179008483887\n","Inner Step: 242, Loss: 0.2660437822341919\n","Inner Step: 243, Loss: 0.26811569929122925\n","Inner Step: 244, Loss: 0.2681547999382019\n","Inner Step: 245, Loss: 0.26810377836227417\n","Inner Step: 246, Loss: 0.2642366290092468\n","Inner Step: 247, Loss: 0.2662090063095093\n","Inner Step: 248, Loss: 0.27436232566833496\n","Inner Step: 249, Loss: 0.2671690583229065\n","Inner Step: 250, Loss: 0.2645154595375061\n","Inner Step: 251, Loss: 0.26219117641448975\n","Inner Step: 252, Loss: 0.2639644145965576\n","Inner Step: 253, Loss: 0.26990580558776855\n","Inner Step: 254, Loss: 0.26519185304641724\n","Inner Step: 255, Loss: 0.2636699676513672\n","Inner Step: 256, Loss: 0.26030731201171875\n","Inner Step: 257, Loss: 0.2602325677871704\n","Inner Step: 258, Loss: 0.2633790969848633\n","Inner Step: 259, Loss: 0.2645108699798584\n","Inner Step: 260, Loss: 0.2722361087799072\n","Inner Step: 261, Loss: 0.26569777727127075\n","Inner Step: 262, Loss: 0.2641794681549072\n","Inner Step: 263, Loss: 0.2579403519630432\n","Inner Step: 264, Loss: 0.26124823093414307\n","Inner Step: 265, Loss: 0.27734243869781494\n","Inner Step: 266, Loss: 0.2691727876663208\n","Inner Step: 267, Loss: 0.26742327213287354\n","Inner Step: 268, Loss: 0.2570485472679138\n","Inner Step: 269, Loss: 0.26761525869369507\n","Inner Step: 270, Loss: 0.2911757826805115\n","Inner Step: 271, Loss: 0.2556583285331726\n","Inner Step: 272, Loss: 0.28520071506500244\n","Inner Step: 273, Loss: 0.32114535570144653\n","Inner Step: 274, Loss: 0.28176790475845337\n","Inner Step: 275, Loss: 0.33280783891677856\n","Inner Step: 276, Loss: 0.26739126443862915\n","Inner Step: 277, Loss: 0.307667076587677\n","Inner Step: 278, Loss: 0.27926039695739746\n","Inner Step: 279, Loss: 0.29779648780822754\n","Inner Step: 280, Loss: 0.26345592737197876\n","Inner Step: 281, Loss: 0.2936418056488037\n","Inner Step: 282, Loss: 0.2654106020927429\n","Inner Step: 283, Loss: 0.29359614849090576\n","Inner Step: 284, Loss: 0.25713902711868286\n","Inner Step: 285, Loss: 0.27832508087158203\n","Inner Step: 286, Loss: 0.25867360830307007\n","Inner Step: 287, Loss: 0.27730947732925415\n","Inner Step: 288, Loss: 0.255298376083374\n","Inner Step: 289, Loss: 0.2686222791671753\n","Inner Step: 290, Loss: 0.25434595346450806\n","Inner Step: 291, Loss: 0.26954859495162964\n","Inner Step: 292, Loss: 0.25774163007736206\n","Inner Step: 293, Loss: 0.262642502784729\n","Inner Step: 294, Loss: 0.25654083490371704\n","Inner Step: 295, Loss: 0.26002436876296997\n","Inner Step: 296, Loss: 0.25643330812454224\n","Inner Step: 297, Loss: 0.25859493017196655\n","Inner Step: 298, Loss: 0.25448381900787354\n","Inner Step: 299, Loss: 0.254814088344574\n","Inner Step: 300, Loss: 0.2565627098083496\n","Inner Step: 301, Loss: 0.2511054277420044\n","Inner Step: 302, Loss: 0.25385165214538574\n","Inner Step: 303, Loss: 0.2492731809616089\n","Inner Step: 304, Loss: 0.25225478410720825\n","Inner Step: 305, Loss: 0.24811315536499023\n","Inner Step: 306, Loss: 0.25041770935058594\n","Inner Step: 307, Loss: 0.24833732843399048\n","Inner Step: 308, Loss: 0.24807655811309814\n","Inner Step: 309, Loss: 0.24830198287963867\n","Inner Step: 310, Loss: 0.24600529670715332\n","Inner Step: 311, Loss: 0.24756956100463867\n","Inner Step: 312, Loss: 0.24544501304626465\n","Inner Step: 313, Loss: 0.2461475133895874\n","Inner Step: 314, Loss: 0.24592536687850952\n","Inner Step: 315, Loss: 0.24395537376403809\n","Inner Step: 316, Loss: 0.24534958600997925\n","Inner Step: 317, Loss: 0.24414604902267456\n","Inner Step: 318, Loss: 0.2427157759666443\n","Inner Step: 319, Loss: 0.24361926317214966\n","Inner Step: 320, Loss: 0.24272143840789795\n","Inner Step: 321, Loss: 0.2413696050643921\n","Inner Step: 322, Loss: 0.24166899919509888\n","Inner Step: 323, Loss: 0.24201560020446777\n","Inner Step: 324, Loss: 0.240892231464386\n","Inner Step: 325, Loss: 0.23990213871002197\n","Inner Step: 326, Loss: 0.23968499898910522\n","Inner Step: 327, Loss: 0.23983991146087646\n","Inner Step: 328, Loss: 0.23993289470672607\n","Inner Step: 329, Loss: 0.23972153663635254\n","Inner Step: 330, Loss: 0.23933279514312744\n","Inner Step: 331, Loss: 0.23890304565429688\n","Inner Step: 332, Loss: 0.23869991302490234\n","Inner Step: 333, Loss: 0.2384941577911377\n","Inner Step: 334, Loss: 0.23845547437667847\n","Inner Step: 335, Loss: 0.23862320184707642\n","Inner Step: 336, Loss: 0.23897457122802734\n","Inner Step: 337, Loss: 0.23955732583999634\n","Inner Step: 338, Loss: 0.2406894564628601\n","Inner Step: 339, Loss: 0.24034017324447632\n","Inner Step: 340, Loss: 0.23915553092956543\n","Inner Step: 341, Loss: 0.23647934198379517\n","Inner Step: 342, Loss: 0.23465514183044434\n","Inner Step: 343, Loss: 0.23454421758651733\n","Inner Step: 344, Loss: 0.23576760292053223\n","Inner Step: 345, Loss: 0.23870456218719482\n","Inner Step: 346, Loss: 0.24140256643295288\n","Inner Step: 347, Loss: 0.24394553899765015\n","Inner Step: 348, Loss: 0.23882704973220825\n","Inner Step: 349, Loss: 0.23377639055252075\n","Inner Step: 350, Loss: 0.23295336961746216\n","Inner Step: 351, Loss: 0.2374679446220398\n","Inner Step: 352, Loss: 0.24455749988555908\n","Inner Step: 353, Loss: 0.24387043714523315\n","Inner Step: 354, Loss: 0.2390257716178894\n","Inner Step: 355, Loss: 0.2323872447013855\n","Inner Step: 356, Loss: 0.23511749505996704\n","Inner Step: 357, Loss: 0.24122107028961182\n","Inner Step: 358, Loss: 0.2391529679298401\n","Inner Step: 359, Loss: 0.2348003387451172\n","Inner Step: 360, Loss: 0.23079979419708252\n","Inner Step: 361, Loss: 0.23323124647140503\n","Inner Step: 362, Loss: 0.23484790325164795\n","Inner Step: 363, Loss: 0.2330206036567688\n","Inner Step: 364, Loss: 0.2300119400024414\n","Inner Step: 365, Loss: 0.23018741607666016\n","Inner Step: 366, Loss: 0.23237872123718262\n","Inner Step: 367, Loss: 0.23320239782333374\n","Inner Step: 368, Loss: 0.23078680038452148\n","Inner Step: 369, Loss: 0.22792673110961914\n","Inner Step: 370, Loss: 0.23018407821655273\n","Inner Step: 371, Loss: 0.23281526565551758\n","Inner Step: 372, Loss: 0.23581069707870483\n","Inner Step: 373, Loss: 0.23439514636993408\n","Inner Step: 374, Loss: 0.2295171618461609\n","Inner Step: 375, Loss: 0.22692012786865234\n","Inner Step: 376, Loss: 0.22954809665679932\n","Inner Step: 377, Loss: 0.2331508994102478\n","Inner Step: 378, Loss: 0.2312069535255432\n","Inner Step: 379, Loss: 0.2279607653617859\n","Inner Step: 380, Loss: 0.2256244421005249\n","Inner Step: 381, Loss: 0.2273121476173401\n","Inner Step: 382, Loss: 0.22833985090255737\n","Inner Step: 383, Loss: 0.22628122568130493\n","Inner Step: 384, Loss: 0.22425484657287598\n","Inner Step: 385, Loss: 0.22402584552764893\n","Inner Step: 386, Loss: 0.22489428520202637\n","Inner Step: 387, Loss: 0.22547972202301025\n","Inner Step: 388, Loss: 0.2240452766418457\n","Inner Step: 389, Loss: 0.2226954698562622\n","Inner Step: 390, Loss: 0.22242844104766846\n","Inner Step: 391, Loss: 0.22255557775497437\n","Inner Step: 392, Loss: 0.22436654567718506\n","Inner Step: 393, Loss: 0.22666430473327637\n","Inner Step: 394, Loss: 0.23259419202804565\n","Inner Step: 395, Loss: 0.24039846658706665\n","Inner Step: 396, Loss: 0.24944525957107544\n","Inner Step: 397, Loss: 0.22920018434524536\n","Inner Step: 398, Loss: 0.2220955491065979\n","Inner Step: 399, Loss: 0.23132067918777466\n","Inner Step: 400, Loss: 0.237035870552063\n","Test Loss after adaptation: 0.5081773996353149\n","Inner Step: 1, Loss: 0.7344475984573364\n","Inner Step: 2, Loss: 0.6783511638641357\n","Inner Step: 3, Loss: 0.647599458694458\n","Inner Step: 4, Loss: 0.6166555285453796\n","Inner Step: 5, Loss: 0.6043468117713928\n","Inner Step: 6, Loss: 0.5957250595092773\n","Inner Step: 7, Loss: 0.5848495364189148\n","Inner Step: 8, Loss: 0.573661208152771\n","Inner Step: 9, Loss: 0.5696017146110535\n","Inner Step: 10, Loss: 0.5663614273071289\n","Inner Step: 11, Loss: 0.5575587153434753\n","Inner Step: 12, Loss: 0.5522558689117432\n","Inner Step: 13, Loss: 0.5496768951416016\n","Inner Step: 14, Loss: 0.5444422960281372\n","Inner Step: 15, Loss: 0.5392577052116394\n","Inner Step: 16, Loss: 0.5351296663284302\n","Inner Step: 17, Loss: 0.5337834358215332\n","Inner Step: 18, Loss: 0.5313814282417297\n","Inner Step: 19, Loss: 0.5281480550765991\n","Inner Step: 20, Loss: 0.5255370140075684\n","Inner Step: 21, Loss: 0.5236697196960449\n","Inner Step: 22, Loss: 0.520435631275177\n","Inner Step: 23, Loss: 0.5180808305740356\n","Inner Step: 24, Loss: 0.5166113376617432\n","Inner Step: 25, Loss: 0.5142867565155029\n","Inner Step: 26, Loss: 0.5113639831542969\n","Inner Step: 27, Loss: 0.5095219612121582\n","Inner Step: 28, Loss: 0.5069975256919861\n","Inner Step: 29, Loss: 0.5037662982940674\n","Inner Step: 30, Loss: 0.5018608570098877\n","Inner Step: 31, Loss: 0.49976885318756104\n","Inner Step: 32, Loss: 0.4976816177368164\n","Inner Step: 33, Loss: 0.49603545665740967\n","Inner Step: 34, Loss: 0.4937872290611267\n","Inner Step: 35, Loss: 0.4919665455818176\n","Inner Step: 36, Loss: 0.4896671772003174\n","Inner Step: 37, Loss: 0.48774898052215576\n","Inner Step: 38, Loss: 0.48600542545318604\n","Inner Step: 39, Loss: 0.4838743805885315\n","Inner Step: 40, Loss: 0.4816994071006775\n","Inner Step: 41, Loss: 0.4791794419288635\n","Inner Step: 42, Loss: 0.47718048095703125\n","Inner Step: 43, Loss: 0.4749688506126404\n","Inner Step: 44, Loss: 0.473039448261261\n","Inner Step: 45, Loss: 0.4704805612564087\n","Inner Step: 46, Loss: 0.4685354232788086\n","Inner Step: 47, Loss: 0.4667063355445862\n","Inner Step: 48, Loss: 0.4644995927810669\n","Inner Step: 49, Loss: 0.46243155002593994\n","Inner Step: 50, Loss: 0.4604201912879944\n","Inner Step: 51, Loss: 0.4584813117980957\n","Inner Step: 52, Loss: 0.4566560387611389\n","Inner Step: 53, Loss: 0.4550057053565979\n","Inner Step: 54, Loss: 0.45353496074676514\n","Inner Step: 55, Loss: 0.45268750190734863\n","Inner Step: 56, Loss: 0.4514577388763428\n","Inner Step: 57, Loss: 0.4490911364555359\n","Inner Step: 58, Loss: 0.44766825437545776\n","Inner Step: 59, Loss: 0.4466589093208313\n","Inner Step: 60, Loss: 0.44444888830184937\n","Inner Step: 61, Loss: 0.4424174427986145\n","Inner Step: 62, Loss: 0.4407215714454651\n","Inner Step: 63, Loss: 0.43949049711227417\n","Inner Step: 64, Loss: 0.43882036209106445\n","Inner Step: 65, Loss: 0.44111955165863037\n","Inner Step: 66, Loss: 0.4475308060646057\n","Inner Step: 67, Loss: 0.4358628988265991\n","Inner Step: 68, Loss: 0.4354233145713806\n","Inner Step: 69, Loss: 0.44021427631378174\n","Inner Step: 70, Loss: 0.4311337471008301\n","Inner Step: 71, Loss: 0.43937790393829346\n","Inner Step: 72, Loss: 0.43224966526031494\n","Inner Step: 73, Loss: 0.43155837059020996\n","Inner Step: 74, Loss: 0.43272340297698975\n","Inner Step: 75, Loss: 0.4261994957923889\n","Inner Step: 76, Loss: 0.4285070300102234\n","Inner Step: 77, Loss: 0.4242163300514221\n","Inner Step: 78, Loss: 0.42565417289733887\n","Inner Step: 79, Loss: 0.4246002435684204\n","Inner Step: 80, Loss: 0.4209522008895874\n","Inner Step: 81, Loss: 0.423883855342865\n","Inner Step: 82, Loss: 0.4202602505683899\n","Inner Step: 83, Loss: 0.4183666706085205\n","Inner Step: 84, Loss: 0.4199194312095642\n","Inner Step: 85, Loss: 0.4165557026863098\n","Inner Step: 86, Loss: 0.41483455896377563\n","Inner Step: 87, Loss: 0.4158056378364563\n","Inner Step: 88, Loss: 0.41324150562286377\n","Inner Step: 89, Loss: 0.4112628698348999\n","Inner Step: 90, Loss: 0.41085368394851685\n","Inner Step: 91, Loss: 0.41029858589172363\n","Inner Step: 92, Loss: 0.4098737835884094\n","Inner Step: 93, Loss: 0.4097943902015686\n","Inner Step: 94, Loss: 0.4090908169746399\n","Inner Step: 95, Loss: 0.4089541435241699\n","Inner Step: 96, Loss: 0.4078221321105957\n","Inner Step: 97, Loss: 0.4056575298309326\n","Inner Step: 98, Loss: 0.4032832384109497\n","Inner Step: 99, Loss: 0.40145254135131836\n","Inner Step: 100, Loss: 0.4022541642189026\n","Inner Step: 101, Loss: 0.40480226278305054\n","Inner Step: 102, Loss: 0.4076768159866333\n","Inner Step: 103, Loss: 0.40179163217544556\n","Inner Step: 104, Loss: 0.3971714377403259\n","Inner Step: 105, Loss: 0.3967406153678894\n","Inner Step: 106, Loss: 0.3991525173187256\n","Inner Step: 107, Loss: 0.4011715054512024\n","Inner Step: 108, Loss: 0.3961137533187866\n","Inner Step: 109, Loss: 0.3927385210990906\n","Inner Step: 110, Loss: 0.39294445514678955\n","Inner Step: 111, Loss: 0.39439189434051514\n","Inner Step: 112, Loss: 0.3968944549560547\n","Inner Step: 113, Loss: 0.3923916816711426\n","Inner Step: 114, Loss: 0.3886234164237976\n","Inner Step: 115, Loss: 0.3885037302970886\n","Inner Step: 116, Loss: 0.3915709853172302\n","Inner Step: 117, Loss: 0.397122859954834\n","Inner Step: 118, Loss: 0.3894404172897339\n","Inner Step: 119, Loss: 0.38449424505233765\n","Inner Step: 120, Loss: 0.3853408694267273\n","Inner Step: 121, Loss: 0.3895489573478699\n","Inner Step: 122, Loss: 0.3951173424720764\n","Inner Step: 123, Loss: 0.38643038272857666\n","Inner Step: 124, Loss: 0.38091081380844116\n","Inner Step: 125, Loss: 0.3839713931083679\n","Inner Step: 126, Loss: 0.3859539031982422\n","Inner Step: 127, Loss: 0.38559889793395996\n","Inner Step: 128, Loss: 0.3792019486427307\n","Inner Step: 129, Loss: 0.37969571352005005\n","Inner Step: 130, Loss: 0.3841680884361267\n","Inner Step: 131, Loss: 0.3798617124557495\n","Inner Step: 132, Loss: 0.37553125619888306\n","Inner Step: 133, Loss: 0.3765553832054138\n","Inner Step: 134, Loss: 0.37760335206985474\n","Inner Step: 135, Loss: 0.3777690529823303\n","Inner Step: 136, Loss: 0.37360525131225586\n","Inner Step: 137, Loss: 0.3719133734703064\n","Inner Step: 138, Loss: 0.3740631937980652\n","Inner Step: 139, Loss: 0.37329864501953125\n","Inner Step: 140, Loss: 0.3739160895347595\n","Inner Step: 141, Loss: 0.3709709644317627\n","Inner Step: 142, Loss: 0.36886876821517944\n","Inner Step: 143, Loss: 0.3676934838294983\n","Inner Step: 144, Loss: 0.3661641478538513\n","Inner Step: 145, Loss: 0.3663894534111023\n","Inner Step: 146, Loss: 0.36716675758361816\n","Inner Step: 147, Loss: 0.3765762448310852\n","Inner Step: 148, Loss: 0.38557446002960205\n","Inner Step: 149, Loss: 0.39686357975006104\n","Inner Step: 150, Loss: 0.3653753399848938\n","Inner Step: 151, Loss: 0.41185832023620605\n","Inner Step: 152, Loss: 0.39005833864212036\n","Inner Step: 153, Loss: 0.38905996084213257\n","Inner Step: 154, Loss: 0.38982701301574707\n","Inner Step: 155, Loss: 0.3702218532562256\n","Inner Step: 156, Loss: 0.3893645405769348\n","Inner Step: 157, Loss: 0.3721984624862671\n","Inner Step: 158, Loss: 0.388816237449646\n","Inner Step: 159, Loss: 0.36204445362091064\n","Inner Step: 160, Loss: 0.38088977336883545\n","Inner Step: 161, Loss: 0.36198562383651733\n","Inner Step: 162, Loss: 0.38439232110977173\n","Inner Step: 163, Loss: 0.3592700958251953\n","Inner Step: 164, Loss: 0.3702603578567505\n","Inner Step: 165, Loss: 0.35732102394104004\n","Inner Step: 166, Loss: 0.36629873514175415\n","Inner Step: 167, Loss: 0.3591613173484802\n","Inner Step: 168, Loss: 0.3601314425468445\n","Inner Step: 169, Loss: 0.3597257733345032\n","Inner Step: 170, Loss: 0.3546332120895386\n","Inner Step: 171, Loss: 0.35767000913619995\n","Inner Step: 172, Loss: 0.3528220057487488\n","Inner Step: 173, Loss: 0.35711878538131714\n","Inner Step: 174, Loss: 0.35287803411483765\n","Inner Step: 175, Loss: 0.35271692276000977\n","Inner Step: 176, Loss: 0.3540859818458557\n","Inner Step: 177, Loss: 0.3494418263435364\n","Inner Step: 178, Loss: 0.3510088324546814\n","Inner Step: 179, Loss: 0.35055404901504517\n","Inner Step: 180, Loss: 0.34752464294433594\n","Inner Step: 181, Loss: 0.3478935956954956\n","Inner Step: 182, Loss: 0.347831130027771\n","Inner Step: 183, Loss: 0.34606534242630005\n","Inner Step: 184, Loss: 0.34505754709243774\n","Inner Step: 185, Loss: 0.34573161602020264\n","Inner Step: 186, Loss: 0.34601402282714844\n","Inner Step: 187, Loss: 0.3440195322036743\n","Inner Step: 188, Loss: 0.3425489068031311\n","Inner Step: 189, Loss: 0.34163010120391846\n","Inner Step: 190, Loss: 0.341217041015625\n","Inner Step: 191, Loss: 0.3413304090499878\n","Inner Step: 192, Loss: 0.34240275621414185\n","Inner Step: 193, Loss: 0.34702157974243164\n","Inner Step: 194, Loss: 0.34604400396347046\n","Inner Step: 195, Loss: 0.3471672534942627\n","Inner Step: 196, Loss: 0.33979642391204834\n","Inner Step: 197, Loss: 0.3377138376235962\n","Inner Step: 198, Loss: 0.33951640129089355\n","Inner Step: 199, Loss: 0.34300798177719116\n","Inner Step: 200, Loss: 0.354728639125824\n","Inner Step: 201, Loss: 0.33855128288269043\n","Inner Step: 202, Loss: 0.33517390489578247\n","Inner Step: 203, Loss: 0.33923786878585815\n","Inner Step: 204, Loss: 0.34108418226242065\n","Inner Step: 205, Loss: 0.3464234471321106\n","Inner Step: 206, Loss: 0.33434993028640747\n","Inner Step: 207, Loss: 0.3363956809043884\n","Inner Step: 208, Loss: 0.35202300548553467\n","Inner Step: 209, Loss: 0.3354641795158386\n","Inner Step: 210, Loss: 0.33347344398498535\n","Inner Step: 211, Loss: 0.34428757429122925\n","Inner Step: 212, Loss: 0.3333338499069214\n","Inner Step: 213, Loss: 0.33054840564727783\n","Inner Step: 214, Loss: 0.3315686583518982\n","Inner Step: 215, Loss: 0.3314169645309448\n","Inner Step: 216, Loss: 0.3341844081878662\n","Inner Step: 217, Loss: 0.32912707328796387\n","Inner Step: 218, Loss: 0.327960729598999\n","Inner Step: 219, Loss: 0.32836437225341797\n","Inner Step: 220, Loss: 0.3297949433326721\n","Inner Step: 221, Loss: 0.3366817235946655\n","Inner Step: 222, Loss: 0.3308948874473572\n","Inner Step: 223, Loss: 0.3318384289741516\n","Inner Step: 224, Loss: 0.32627636194229126\n","Inner Step: 225, Loss: 0.3264896869659424\n","Inner Step: 226, Loss: 0.33261972665786743\n","Inner Step: 227, Loss: 0.3284624218940735\n","Inner Step: 228, Loss: 0.33001214265823364\n","Inner Step: 229, Loss: 0.3250585198402405\n","Inner Step: 230, Loss: 0.32355624437332153\n","Inner Step: 231, Loss: 0.32219552993774414\n","Inner Step: 232, Loss: 0.3223130702972412\n","Inner Step: 233, Loss: 0.3245764374732971\n","Inner Step: 234, Loss: 0.326408326625824\n","Inner Step: 235, Loss: 0.33907389640808105\n","Inner Step: 236, Loss: 0.32779210805892944\n","Inner Step: 237, Loss: 0.3248107433319092\n","Inner Step: 238, Loss: 0.32028836011886597\n","Inner Step: 239, Loss: 0.32338207960128784\n","Inner Step: 240, Loss: 0.33847784996032715\n","Inner Step: 241, Loss: 0.32504570484161377\n","Inner Step: 242, Loss: 0.32202619314193726\n","Inner Step: 243, Loss: 0.31827253103256226\n","Inner Step: 244, Loss: 0.31856030225753784\n","Inner Step: 245, Loss: 0.3235238790512085\n","Inner Step: 246, Loss: 0.32050246000289917\n","Inner Step: 247, Loss: 0.3207316994667053\n","Inner Step: 248, Loss: 0.3177540898323059\n","Inner Step: 249, Loss: 0.31651753187179565\n","Inner Step: 250, Loss: 0.31525689363479614\n","Inner Step: 251, Loss: 0.31461024284362793\n","Inner Step: 252, Loss: 0.31576019525527954\n","Inner Step: 253, Loss: 0.31805962324142456\n","Inner Step: 254, Loss: 0.3315325379371643\n","Inner Step: 255, Loss: 0.3219614028930664\n","Inner Step: 256, Loss: 0.32080280780792236\n","Inner Step: 257, Loss: 0.3143951892852783\n","Inner Step: 258, Loss: 0.31478917598724365\n","Inner Step: 259, Loss: 0.3225429058074951\n","Inner Step: 260, Loss: 0.3152428865432739\n","Inner Step: 261, Loss: 0.3149595856666565\n","Inner Step: 262, Loss: 0.31457632780075073\n","Inner Step: 263, Loss: 0.3190840482711792\n","Inner Step: 264, Loss: 0.3153257369995117\n","Inner Step: 265, Loss: 0.31291311979293823\n","Inner Step: 266, Loss: 0.3146657347679138\n","Inner Step: 267, Loss: 0.3131745457649231\n","Inner Step: 268, Loss: 0.3153546452522278\n","Inner Step: 269, Loss: 0.31214791536331177\n","Inner Step: 270, Loss: 0.3155350685119629\n","Inner Step: 271, Loss: 0.3143270015716553\n","Inner Step: 272, Loss: 0.3161226511001587\n","Inner Step: 273, Loss: 0.3237758278846741\n","Inner Step: 274, Loss: 0.31247764825820923\n","Inner Step: 275, Loss: 0.30743205547332764\n","Inner Step: 276, Loss: 0.30846965312957764\n","Inner Step: 277, Loss: 0.3117271661758423\n","Inner Step: 278, Loss: 0.3216359615325928\n","Inner Step: 279, Loss: 0.3105962872505188\n","Inner Step: 280, Loss: 0.30536890029907227\n","Inner Step: 281, Loss: 0.3050066828727722\n","Inner Step: 282, Loss: 0.3076446056365967\n","Inner Step: 283, Loss: 0.3179171085357666\n","Inner Step: 284, Loss: 0.31072700023651123\n","Inner Step: 285, Loss: 0.3116939067840576\n","Inner Step: 286, Loss: 0.3037222623825073\n","Inner Step: 287, Loss: 0.3044314980506897\n","Inner Step: 288, Loss: 0.3099505305290222\n","Inner Step: 289, Loss: 0.306888222694397\n","Inner Step: 290, Loss: 0.30880457162857056\n","Inner Step: 291, Loss: 0.3032309412956238\n","Inner Step: 292, Loss: 0.30108189582824707\n","Inner Step: 293, Loss: 0.30024152994155884\n","Inner Step: 294, Loss: 0.30077457427978516\n","Inner Step: 295, Loss: 0.3022441864013672\n","Inner Step: 296, Loss: 0.30214637517929077\n","Inner Step: 297, Loss: 0.30661487579345703\n","Inner Step: 298, Loss: 0.3064563274383545\n","Inner Step: 299, Loss: 0.31776201725006104\n","Inner Step: 300, Loss: 0.3039247989654541\n","Inner Step: 301, Loss: 0.298292338848114\n","Inner Step: 302, Loss: 0.2992381453514099\n","Inner Step: 303, Loss: 0.30303114652633667\n","Inner Step: 304, Loss: 0.3168039917945862\n","Inner Step: 305, Loss: 0.30419522523880005\n","Inner Step: 306, Loss: 0.3009553551673889\n","Inner Step: 307, Loss: 0.2964288592338562\n","Inner Step: 308, Loss: 0.29830628633499146\n","Inner Step: 309, Loss: 0.30336207151412964\n","Inner Step: 310, Loss: 0.30122804641723633\n","Inner Step: 311, Loss: 0.3005021810531616\n","Inner Step: 312, Loss: 0.29583245515823364\n","Inner Step: 313, Loss: 0.29413700103759766\n","Inner Step: 314, Loss: 0.2954961657524109\n","Inner Step: 315, Loss: 0.2958680987358093\n","Inner Step: 316, Loss: 0.29770326614379883\n","Inner Step: 317, Loss: 0.2957671284675598\n","Inner Step: 318, Loss: 0.2959865927696228\n","Inner Step: 319, Loss: 0.2933584451675415\n","Inner Step: 320, Loss: 0.29193365573883057\n","Inner Step: 321, Loss: 0.29151344299316406\n","Inner Step: 322, Loss: 0.29226917028427124\n","Inner Step: 323, Loss: 0.2959928512573242\n","Inner Step: 324, Loss: 0.3021277189254761\n","Inner Step: 325, Loss: 0.3325519561767578\n","Inner Step: 326, Loss: 0.2968043088912964\n","Inner Step: 327, Loss: 0.29250234365463257\n","Inner Step: 328, Loss: 0.306870698928833\n","Inner Step: 329, Loss: 0.29833489656448364\n","Inner Step: 330, Loss: 0.29566943645477295\n","Inner Step: 331, Loss: 0.2902860641479492\n","Inner Step: 332, Loss: 0.2897259593009949\n","Inner Step: 333, Loss: 0.2926943898200989\n","Inner Step: 334, Loss: 0.29194313287734985\n","Inner Step: 335, Loss: 0.29229027032852173\n","Inner Step: 336, Loss: 0.289193332195282\n","Inner Step: 337, Loss: 0.28787124156951904\n","Inner Step: 338, Loss: 0.2868692874908447\n","Inner Step: 339, Loss: 0.287169873714447\n","Inner Step: 340, Loss: 0.28984564542770386\n","Inner Step: 341, Loss: 0.29259878396987915\n","Inner Step: 342, Loss: 0.30618661642074585\n","Inner Step: 343, Loss: 0.29472607374191284\n","Inner Step: 344, Loss: 0.29555583000183105\n","Inner Step: 345, Loss: 0.2869698405265808\n","Inner Step: 346, Loss: 0.2846894860267639\n","Inner Step: 347, Loss: 0.28715580701828003\n","Inner Step: 348, Loss: 0.28908413648605347\n","Inner Step: 349, Loss: 0.29621005058288574\n","Inner Step: 350, Loss: 0.29047155380249023\n","Inner Step: 351, Loss: 0.29113560914993286\n","Inner Step: 352, Loss: 0.2845802903175354\n","Inner Step: 353, Loss: 0.2826598286628723\n","Inner Step: 354, Loss: 0.285169780254364\n","Inner Step: 355, Loss: 0.2859688401222229\n","Inner Step: 356, Loss: 0.28975558280944824\n","Inner Step: 357, Loss: 0.2857314944267273\n","Inner Step: 358, Loss: 0.28589099645614624\n","Inner Step: 359, Loss: 0.28216809034347534\n","Inner Step: 360, Loss: 0.2809063196182251\n","Inner Step: 361, Loss: 0.27998632192611694\n","Inner Step: 362, Loss: 0.28091156482696533\n","Inner Step: 363, Loss: 0.28481560945510864\n","Inner Step: 364, Loss: 0.2889971137046814\n","Inner Step: 365, Loss: 0.3058696985244751\n","Inner Step: 366, Loss: 0.2886219620704651\n","Inner Step: 367, Loss: 0.28326117992401123\n","Inner Step: 368, Loss: 0.2797517776489258\n","Inner Step: 369, Loss: 0.2797850966453552\n","Inner Step: 370, Loss: 0.28411567211151123\n","Inner Step: 371, Loss: 0.28497159481048584\n","Inner Step: 372, Loss: 0.2945724129676819\n","Inner Step: 373, Loss: 0.28667283058166504\n","Inner Step: 374, Loss: 0.2851217985153198\n","Inner Step: 375, Loss: 0.2780306935310364\n","Inner Step: 376, Loss: 0.2781737446784973\n","Inner Step: 377, Loss: 0.28402209281921387\n","Inner Step: 378, Loss: 0.2839384078979492\n","Inner Step: 379, Loss: 0.28919804096221924\n","Inner Step: 380, Loss: 0.28135740756988525\n","Inner Step: 381, Loss: 0.2770601511001587\n","Inner Step: 382, Loss: 0.2758873701095581\n","Inner Step: 383, Loss: 0.27933359146118164\n","Inner Step: 384, Loss: 0.28709715604782104\n","Inner Step: 385, Loss: 0.28311002254486084\n","Inner Step: 386, Loss: 0.2839762568473816\n","Inner Step: 387, Loss: 0.27621978521347046\n","Inner Step: 388, Loss: 0.2753046751022339\n","Inner Step: 389, Loss: 0.27937060594558716\n","Inner Step: 390, Loss: 0.27793920040130615\n","Inner Step: 391, Loss: 0.27734947204589844\n","Inner Step: 392, Loss: 0.2735137343406677\n","Inner Step: 393, Loss: 0.2729138731956482\n","Inner Step: 394, Loss: 0.2747654318809509\n","Inner Step: 395, Loss: 0.27435600757598877\n","Inner Step: 396, Loss: 0.274466872215271\n","Inner Step: 397, Loss: 0.27240872383117676\n","Inner Step: 398, Loss: 0.2713836431503296\n","Inner Step: 399, Loss: 0.27063941955566406\n","Inner Step: 400, Loss: 0.2703911066055298\n","Test Loss after adaptation: 0.5234296321868896\n","Inner Step: 1, Loss: 0.6451402902603149\n","Inner Step: 2, Loss: 0.5969595909118652\n","Inner Step: 3, Loss: 0.5633175373077393\n","Inner Step: 4, Loss: 0.53267502784729\n","Inner Step: 5, Loss: 0.5182856321334839\n","Inner Step: 6, Loss: 0.5068046450614929\n","Inner Step: 7, Loss: 0.493846595287323\n","Inner Step: 8, Loss: 0.4815516471862793\n","Inner Step: 9, Loss: 0.4726824164390564\n","Inner Step: 10, Loss: 0.4670548439025879\n","Inner Step: 11, Loss: 0.45938509702682495\n","Inner Step: 12, Loss: 0.4514269232749939\n","Inner Step: 13, Loss: 0.44589483737945557\n","Inner Step: 14, Loss: 0.44153153896331787\n","Inner Step: 15, Loss: 0.43743669986724854\n","Inner Step: 16, Loss: 0.4329947829246521\n","Inner Step: 17, Loss: 0.42980438470840454\n","Inner Step: 18, Loss: 0.4267846941947937\n","Inner Step: 19, Loss: 0.4227765202522278\n","Inner Step: 20, Loss: 0.42000812292099\n","Inner Step: 21, Loss: 0.4180105924606323\n","Inner Step: 22, Loss: 0.4165358543395996\n","Inner Step: 23, Loss: 0.41496145725250244\n","Inner Step: 24, Loss: 0.41315168142318726\n","Inner Step: 25, Loss: 0.41152334213256836\n","Inner Step: 26, Loss: 0.4099181890487671\n","Inner Step: 27, Loss: 0.40851038694381714\n","Inner Step: 28, Loss: 0.4070160984992981\n","Inner Step: 29, Loss: 0.4057121276855469\n","Inner Step: 30, Loss: 0.40420228242874146\n","Inner Step: 31, Loss: 0.40222668647766113\n","Inner Step: 32, Loss: 0.4003381133079529\n","Inner Step: 33, Loss: 0.39896833896636963\n","Inner Step: 34, Loss: 0.3971825838088989\n","Inner Step: 35, Loss: 0.39538758993148804\n","Inner Step: 36, Loss: 0.39397895336151123\n","Inner Step: 37, Loss: 0.39231252670288086\n","Inner Step: 38, Loss: 0.3909754753112793\n","Inner Step: 39, Loss: 0.38932710886001587\n","Inner Step: 40, Loss: 0.3877384066581726\n","Inner Step: 41, Loss: 0.38616615533828735\n","Inner Step: 42, Loss: 0.38474220037460327\n","Inner Step: 43, Loss: 0.3830934166908264\n","Inner Step: 44, Loss: 0.3815939426422119\n","Inner Step: 45, Loss: 0.38004952669143677\n","Inner Step: 46, Loss: 0.37862658500671387\n","Inner Step: 47, Loss: 0.3771083354949951\n","Inner Step: 48, Loss: 0.37551528215408325\n","Inner Step: 49, Loss: 0.37401944398880005\n","Inner Step: 50, Loss: 0.3725072741508484\n","Inner Step: 51, Loss: 0.3709874153137207\n","Inner Step: 52, Loss: 0.36954158544540405\n","Inner Step: 53, Loss: 0.36806720495224\n","Inner Step: 54, Loss: 0.3664592504501343\n","Inner Step: 55, Loss: 0.3648359179496765\n","Inner Step: 56, Loss: 0.36327028274536133\n","Inner Step: 57, Loss: 0.3616827130317688\n","Inner Step: 58, Loss: 0.36009734869003296\n","Inner Step: 59, Loss: 0.3587515950202942\n","Inner Step: 60, Loss: 0.35808616876602173\n","Inner Step: 61, Loss: 0.3604254126548767\n","Inner Step: 62, Loss: 0.3566838502883911\n","Inner Step: 63, Loss: 0.3538791537284851\n","Inner Step: 64, Loss: 0.3538450598716736\n","Inner Step: 65, Loss: 0.35244667530059814\n","Inner Step: 66, Loss: 0.35021400451660156\n","Inner Step: 67, Loss: 0.34851789474487305\n","Inner Step: 68, Loss: 0.34801286458969116\n","Inner Step: 69, Loss: 0.3474690914154053\n","Inner Step: 70, Loss: 0.3448421359062195\n","Inner Step: 71, Loss: 0.34348350763320923\n","Inner Step: 72, Loss: 0.34420061111450195\n","Inner Step: 73, Loss: 0.3467521071434021\n","Inner Step: 74, Loss: 0.34875768423080444\n","Inner Step: 75, Loss: 0.3398481011390686\n","Inner Step: 76, Loss: 0.3434762954711914\n","Inner Step: 77, Loss: 0.34667426347732544\n","Inner Step: 78, Loss: 0.3369287848472595\n","Inner Step: 79, Loss: 0.3482591509819031\n","Inner Step: 80, Loss: 0.3373565673828125\n","Inner Step: 81, Loss: 0.3394051194190979\n","Inner Step: 82, Loss: 0.3380278944969177\n","Inner Step: 83, Loss: 0.3347228765487671\n","Inner Step: 84, Loss: 0.3372507691383362\n","Inner Step: 85, Loss: 0.3312340974807739\n","Inner Step: 86, Loss: 0.3357352614402771\n","Inner Step: 87, Loss: 0.3321787714958191\n","Inner Step: 88, Loss: 0.33059990406036377\n","Inner Step: 89, Loss: 0.33240431547164917\n","Inner Step: 90, Loss: 0.32763057947158813\n","Inner Step: 91, Loss: 0.32941561937332153\n","Inner Step: 92, Loss: 0.3285259008407593\n","Inner Step: 93, Loss: 0.3260383605957031\n","Inner Step: 94, Loss: 0.3281269073486328\n","Inner Step: 95, Loss: 0.32544803619384766\n","Inner Step: 96, Loss: 0.32459360361099243\n","Inner Step: 97, Loss: 0.325198769569397\n","Inner Step: 98, Loss: 0.32281172275543213\n","Inner Step: 99, Loss: 0.32254117727279663\n","Inner Step: 100, Loss: 0.32293111085891724\n","Inner Step: 101, Loss: 0.3211602568626404\n","Inner Step: 102, Loss: 0.31966525316238403\n","Inner Step: 103, Loss: 0.3201127052307129\n","Inner Step: 104, Loss: 0.3222981095314026\n","Inner Step: 105, Loss: 0.32079440355300903\n","Inner Step: 106, Loss: 0.31906217336654663\n","Inner Step: 107, Loss: 0.31691479682922363\n","Inner Step: 108, Loss: 0.31619149446487427\n","Inner Step: 109, Loss: 0.31630760431289673\n","Inner Step: 110, Loss: 0.31587493419647217\n","Inner Step: 111, Loss: 0.3150638937950134\n","Inner Step: 112, Loss: 0.31383174657821655\n","Inner Step: 113, Loss: 0.31323885917663574\n","Inner Step: 114, Loss: 0.31315135955810547\n","Inner Step: 115, Loss: 0.31504184007644653\n","Inner Step: 116, Loss: 0.31597399711608887\n","Inner Step: 117, Loss: 0.32302629947662354\n","Inner Step: 118, Loss: 0.3148075342178345\n","Inner Step: 119, Loss: 0.3106718063354492\n","Inner Step: 120, Loss: 0.31230807304382324\n","Inner Step: 121, Loss: 0.310634970664978\n","Inner Step: 122, Loss: 0.3089708685874939\n","Inner Step: 123, Loss: 0.30844759941101074\n","Inner Step: 124, Loss: 0.30962687730789185\n","Inner Step: 125, Loss: 0.31554800271987915\n","Inner Step: 126, Loss: 0.31412869691848755\n","Inner Step: 127, Loss: 0.3128213882446289\n","Inner Step: 128, Loss: 0.30669474601745605\n","Inner Step: 129, Loss: 0.3120920658111572\n","Inner Step: 130, Loss: 0.3132196068763733\n","Inner Step: 131, Loss: 0.305492639541626\n","Inner Step: 132, Loss: 0.3145143389701843\n","Inner Step: 133, Loss: 0.3192412853240967\n","Inner Step: 134, Loss: 0.30423909425735474\n","Inner Step: 135, Loss: 0.32199257612228394\n","Inner Step: 136, Loss: 0.316131591796875\n","Inner Step: 137, Loss: 0.3098157048225403\n","Inner Step: 138, Loss: 0.3173866868019104\n","Inner Step: 139, Loss: 0.30420517921447754\n","Inner Step: 140, Loss: 0.31292444467544556\n","Inner Step: 141, Loss: 0.3027838468551636\n","Inner Step: 142, Loss: 0.31135010719299316\n","Inner Step: 143, Loss: 0.30342763662338257\n","Inner Step: 144, Loss: 0.305597186088562\n","Inner Step: 145, Loss: 0.30592334270477295\n","Inner Step: 146, Loss: 0.3007148504257202\n","Inner Step: 147, Loss: 0.305919885635376\n","Inner Step: 148, Loss: 0.2997521758079529\n","Inner Step: 149, Loss: 0.3030875325202942\n","Inner Step: 150, Loss: 0.30071693658828735\n","Inner Step: 151, Loss: 0.300021767616272\n","Inner Step: 152, Loss: 0.3009372353553772\n","Inner Step: 153, Loss: 0.2977789640426636\n","Inner Step: 154, Loss: 0.29973548650741577\n","Inner Step: 155, Loss: 0.29756319522857666\n","Inner Step: 156, Loss: 0.2975001335144043\n","Inner Step: 157, Loss: 0.29791581630706787\n","Inner Step: 158, Loss: 0.2958560585975647\n","Inner Step: 159, Loss: 0.297480046749115\n","Inner Step: 160, Loss: 0.2976093888282776\n","Inner Step: 161, Loss: 0.29471755027770996\n","Inner Step: 162, Loss: 0.29747438430786133\n","Inner Step: 163, Loss: 0.2990097999572754\n","Inner Step: 164, Loss: 0.29378730058670044\n","Inner Step: 165, Loss: 0.2961559295654297\n","Inner Step: 166, Loss: 0.3000730276107788\n","Inner Step: 167, Loss: 0.29316914081573486\n","Inner Step: 168, Loss: 0.29570043087005615\n","Inner Step: 169, Loss: 0.3008244037628174\n","Inner Step: 170, Loss: 0.29183995723724365\n","Inner Step: 171, Loss: 0.29950153827667236\n","Inner Step: 172, Loss: 0.3038129210472107\n","Inner Step: 173, Loss: 0.291492223739624\n","Inner Step: 174, Loss: 0.3085128664970398\n","Inner Step: 175, Loss: 0.3052869439125061\n","Inner Step: 176, Loss: 0.29662764072418213\n","Inner Step: 177, Loss: 0.3069397211074829\n","Inner Step: 178, Loss: 0.29129236936569214\n","Inner Step: 179, Loss: 0.30057328939437866\n","Inner Step: 180, Loss: 0.29008013010025024\n","Inner Step: 181, Loss: 0.2998008131980896\n","Inner Step: 182, Loss: 0.29443418979644775\n","Inner Step: 183, Loss: 0.29470574855804443\n","Inner Step: 184, Loss: 0.2943660616874695\n","Inner Step: 185, Loss: 0.2903265953063965\n","Inner Step: 186, Loss: 0.2945883870124817\n","Inner Step: 187, Loss: 0.28922468423843384\n","Inner Step: 188, Loss: 0.29484647512435913\n","Inner Step: 189, Loss: 0.28776997327804565\n","Inner Step: 190, Loss: 0.29149848222732544\n","Inner Step: 191, Loss: 0.28764843940734863\n","Inner Step: 192, Loss: 0.28873682022094727\n","Inner Step: 193, Loss: 0.2898626923561096\n","Inner Step: 194, Loss: 0.2861751317977905\n","Inner Step: 195, Loss: 0.289792537689209\n","Inner Step: 196, Loss: 0.2866172194480896\n","Inner Step: 197, Loss: 0.2875717282295227\n","Inner Step: 198, Loss: 0.28666114807128906\n","Inner Step: 199, Loss: 0.28444600105285645\n","Inner Step: 200, Loss: 0.28663337230682373\n","Inner Step: 201, Loss: 0.2842739224433899\n","Inner Step: 202, Loss: 0.28374582529067993\n","Inner Step: 203, Loss: 0.2848196029663086\n","Inner Step: 204, Loss: 0.2828635573387146\n","Inner Step: 205, Loss: 0.2834417223930359\n","Inner Step: 206, Loss: 0.28496187925338745\n","Inner Step: 207, Loss: 0.2820809483528137\n","Inner Step: 208, Loss: 0.28238874673843384\n","Inner Step: 209, Loss: 0.2843543291091919\n","Inner Step: 210, Loss: 0.28131914138793945\n","Inner Step: 211, Loss: 0.2809014320373535\n","Inner Step: 212, Loss: 0.2830743193626404\n","Inner Step: 213, Loss: 0.28160393238067627\n","Inner Step: 214, Loss: 0.2807268500328064\n","Inner Step: 215, Loss: 0.2795306444168091\n","Inner Step: 216, Loss: 0.28054124116897583\n","Inner Step: 217, Loss: 0.28484565019607544\n","Inner Step: 218, Loss: 0.2827277183532715\n","Inner Step: 219, Loss: 0.28112155199050903\n","Inner Step: 220, Loss: 0.2786141037940979\n","Inner Step: 221, Loss: 0.2805026173591614\n","Inner Step: 222, Loss: 0.2855271100997925\n","Inner Step: 223, Loss: 0.28087931871414185\n","Inner Step: 224, Loss: 0.2781038284301758\n","Inner Step: 225, Loss: 0.2775316834449768\n","Inner Step: 226, Loss: 0.27899330854415894\n","Inner Step: 227, Loss: 0.2813865542411804\n","Inner Step: 228, Loss: 0.2781389355659485\n","Inner Step: 229, Loss: 0.27625221014022827\n","Inner Step: 230, Loss: 0.2757667899131775\n","Inner Step: 231, Loss: 0.2760574221611023\n","Inner Step: 232, Loss: 0.2769460082054138\n","Inner Step: 233, Loss: 0.27743589878082275\n","Inner Step: 234, Loss: 0.27881014347076416\n","Inner Step: 235, Loss: 0.27734214067459106\n","Inner Step: 236, Loss: 0.27480530738830566\n","Inner Step: 237, Loss: 0.27352041006088257\n","Inner Step: 238, Loss: 0.27514517307281494\n","Inner Step: 239, Loss: 0.2802157402038574\n","Inner Step: 240, Loss: 0.28101325035095215\n","Inner Step: 241, Loss: 0.28030455112457275\n","Inner Step: 242, Loss: 0.27394217252731323\n","Inner Step: 243, Loss: 0.27516382932662964\n","Inner Step: 244, Loss: 0.28331196308135986\n","Inner Step: 245, Loss: 0.27654868364334106\n","Inner Step: 246, Loss: 0.2725866436958313\n","Inner Step: 247, Loss: 0.273277223110199\n","Inner Step: 248, Loss: 0.2739105820655823\n","Inner Step: 249, Loss: 0.27417564392089844\n","Inner Step: 250, Loss: 0.27252089977264404\n","Inner Step: 251, Loss: 0.27054363489151\n","Inner Step: 252, Loss: 0.27050191164016724\n","Inner Step: 253, Loss: 0.2699575424194336\n","Inner Step: 254, Loss: 0.2695276737213135\n","Inner Step: 255, Loss: 0.2706926465034485\n","Inner Step: 256, Loss: 0.27210289239883423\n","Inner Step: 257, Loss: 0.2756122946739197\n","Inner Step: 258, Loss: 0.279227077960968\n","Inner Step: 259, Loss: 0.2716939449310303\n","Inner Step: 260, Loss: 0.26902246475219727\n","Inner Step: 261, Loss: 0.2760760188102722\n","Inner Step: 262, Loss: 0.2788870334625244\n","Inner Step: 263, Loss: 0.28145909309387207\n","Inner Step: 264, Loss: 0.27034276723861694\n","Inner Step: 265, Loss: 0.27451783418655396\n","Inner Step: 266, Loss: 0.2803541421890259\n","Inner Step: 267, Loss: 0.2684764266014099\n","Inner Step: 268, Loss: 0.2704249620437622\n","Inner Step: 269, Loss: 0.27849632501602173\n","Inner Step: 270, Loss: 0.26917165517807007\n","Inner Step: 271, Loss: 0.269931435585022\n","Inner Step: 272, Loss: 0.27807217836380005\n","Inner Step: 273, Loss: 0.2683725953102112\n","Inner Step: 274, Loss: 0.26621323823928833\n","Inner Step: 275, Loss: 0.2716526985168457\n","Inner Step: 276, Loss: 0.2667387127876282\n","Inner Step: 277, Loss: 0.2655527591705322\n","Inner Step: 278, Loss: 0.26914024353027344\n","Inner Step: 279, Loss: 0.2665674090385437\n","Inner Step: 280, Loss: 0.2637020945549011\n","Inner Step: 281, Loss: 0.26489830017089844\n","Inner Step: 282, Loss: 0.26538747549057007\n","Inner Step: 283, Loss: 0.26382744312286377\n","Inner Step: 284, Loss: 0.26262903213500977\n","Inner Step: 285, Loss: 0.26370513439178467\n","Inner Step: 286, Loss: 0.26494693756103516\n","Inner Step: 287, Loss: 0.26444393396377563\n","Inner Step: 288, Loss: 0.26341062784194946\n","Inner Step: 289, Loss: 0.26139867305755615\n","Inner Step: 290, Loss: 0.26178932189941406\n","Inner Step: 291, Loss: 0.26402056217193604\n","Inner Step: 292, Loss: 0.2654953598976135\n","Inner Step: 293, Loss: 0.26889824867248535\n","Inner Step: 294, Loss: 0.2648455500602722\n","Inner Step: 295, Loss: 0.2601911425590515\n","Inner Step: 296, Loss: 0.26184511184692383\n","Inner Step: 297, Loss: 0.26818186044692993\n","Inner Step: 298, Loss: 0.2804235816001892\n","Inner Step: 299, Loss: 0.2657448649406433\n","Inner Step: 300, Loss: 0.26503539085388184\n","Inner Step: 301, Loss: 0.2784651517868042\n","Inner Step: 302, Loss: 0.2624296545982361\n","Inner Step: 303, Loss: 0.26028192043304443\n","Inner Step: 304, Loss: 0.26792192459106445\n","Inner Step: 305, Loss: 0.26222360134124756\n","Inner Step: 306, Loss: 0.25869572162628174\n","Inner Step: 307, Loss: 0.2639552354812622\n","Inner Step: 308, Loss: 0.2643585801124573\n","Inner Step: 309, Loss: 0.26311755180358887\n","Inner Step: 310, Loss: 0.25914621353149414\n","Inner Step: 311, Loss: 0.2610939145088196\n","Inner Step: 312, Loss: 0.2629398703575134\n","Inner Step: 313, Loss: 0.25904136896133423\n","Inner Step: 314, Loss: 0.2561338543891907\n","Inner Step: 315, Loss: 0.25694429874420166\n","Inner Step: 316, Loss: 0.25787627696990967\n","Inner Step: 317, Loss: 0.25587964057922363\n","Inner Step: 318, Loss: 0.2551047205924988\n","Inner Step: 319, Loss: 0.2577003240585327\n","Inner Step: 320, Loss: 0.26223552227020264\n","Inner Step: 321, Loss: 0.2613494396209717\n","Inner Step: 322, Loss: 0.25787651538848877\n","Inner Step: 323, Loss: 0.25403350591659546\n","Inner Step: 324, Loss: 0.2573375105857849\n","Inner Step: 325, Loss: 0.26402783393859863\n","Inner Step: 326, Loss: 0.2610228657722473\n","Inner Step: 327, Loss: 0.25812268257141113\n","Inner Step: 328, Loss: 0.25389015674591064\n","Inner Step: 329, Loss: 0.2553238868713379\n","Inner Step: 330, Loss: 0.2591455578804016\n","Inner Step: 331, Loss: 0.2548338770866394\n","Inner Step: 332, Loss: 0.25237101316452026\n","Inner Step: 333, Loss: 0.2530263066291809\n","Inner Step: 334, Loss: 0.2533223032951355\n","Inner Step: 335, Loss: 0.25409430265426636\n","Inner Step: 336, Loss: 0.2522149085998535\n","Inner Step: 337, Loss: 0.2506641149520874\n","Inner Step: 338, Loss: 0.2513369917869568\n","Inner Step: 339, Loss: 0.2513439655303955\n","Inner Step: 340, Loss: 0.2517275810241699\n","Inner Step: 341, Loss: 0.2516806721687317\n","Inner Step: 342, Loss: 0.25239497423171997\n","Inner Step: 343, Loss: 0.25483620166778564\n","Inner Step: 344, Loss: 0.2537328004837036\n","Inner Step: 345, Loss: 0.2517152428627014\n","Inner Step: 346, Loss: 0.25080394744873047\n","Inner Step: 347, Loss: 0.2489938735961914\n","Inner Step: 348, Loss: 0.24829411506652832\n","Inner Step: 349, Loss: 0.24818897247314453\n","Inner Step: 350, Loss: 0.24839502573013306\n","Inner Step: 351, Loss: 0.25006628036499023\n","Inner Step: 352, Loss: 0.25200265645980835\n","Inner Step: 353, Loss: 0.26025503873825073\n","Inner Step: 354, Loss: 0.26195335388183594\n","Inner Step: 355, Loss: 0.25752878189086914\n","Inner Step: 356, Loss: 0.2481306791305542\n","Inner Step: 357, Loss: 0.2517549991607666\n","Inner Step: 358, Loss: 0.2653898000717163\n","Inner Step: 359, Loss: 0.2625037431716919\n","Inner Step: 360, Loss: 0.25552862882614136\n","Inner Step: 361, Loss: 0.24855172634124756\n","Inner Step: 362, Loss: 0.25362151861190796\n","Inner Step: 363, Loss: 0.25842100381851196\n","Inner Step: 364, Loss: 0.24823486804962158\n","Inner Step: 365, Loss: 0.24719923734664917\n","Inner Step: 366, Loss: 0.2546684145927429\n","Inner Step: 367, Loss: 0.25206977128982544\n","Inner Step: 368, Loss: 0.24744462966918945\n","Inner Step: 369, Loss: 0.24549460411071777\n","Inner Step: 370, Loss: 0.24870961904525757\n","Inner Step: 371, Loss: 0.2505318522453308\n","Inner Step: 372, Loss: 0.24571532011032104\n","Inner Step: 373, Loss: 0.2443622350692749\n","Inner Step: 374, Loss: 0.2486451268196106\n","Inner Step: 375, Loss: 0.24879199266433716\n","Inner Step: 376, Loss: 0.24976378679275513\n","Inner Step: 377, Loss: 0.24585378170013428\n","Inner Step: 378, Loss: 0.24380314350128174\n","Inner Step: 379, Loss: 0.24889832735061646\n","Inner Step: 380, Loss: 0.25011229515075684\n","Inner Step: 381, Loss: 0.25122976303100586\n","Inner Step: 382, Loss: 0.2460956573486328\n","Inner Step: 383, Loss: 0.24313557147979736\n","Inner Step: 384, Loss: 0.24857556819915771\n","Inner Step: 385, Loss: 0.25032126903533936\n","Inner Step: 386, Loss: 0.24966740608215332\n","Inner Step: 387, Loss: 0.244573712348938\n","Inner Step: 388, Loss: 0.24430596828460693\n","Inner Step: 389, Loss: 0.24835920333862305\n","Inner Step: 390, Loss: 0.2460232377052307\n","Inner Step: 391, Loss: 0.24174630641937256\n","Inner Step: 392, Loss: 0.24067473411560059\n","Inner Step: 393, Loss: 0.24216949939727783\n","Inner Step: 394, Loss: 0.24220401048660278\n","Inner Step: 395, Loss: 0.24080920219421387\n","Inner Step: 396, Loss: 0.2390204668045044\n","Inner Step: 397, Loss: 0.23949193954467773\n","Inner Step: 398, Loss: 0.2404060959815979\n","Inner Step: 399, Loss: 0.23998761177062988\n","Inner Step: 400, Loss: 0.23905545473098755\n","Test Loss after adaptation: 0.5238887071609497\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":182169,"status":"ok","timestamp":1714775569029,"user":{"displayName":"Nattapon Jaroenchai","userId":"17092454241854925654"},"user_tz":300},"id":"B3ezR9S7t-DL","colab":{"base_uri":"https://localhost:8080/"},"outputId":"cb36316c-dc9b-41a6-a4fd-8fff9fce6a37"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/Meta_learning_research/Notebooks\n"]}],"source":["%cd '/content/drive/MyDrive/Meta_learning_research/Notebooks/'\n","input_data = './samples/'\n","location = \"Covinton\"\n","\n","X_test = np.load('/content/drive/MyDrive/Meta_learning_research/Notebooks/samples/Covington/bottom_half_test_data.npy').astype(np.float32)\n","X_test[X_test < 0] = 0"]},{"cell_type":"code","source":["# This normalization_type was define on the top of the notebook for the dataloader\n","if normalization_type == '0':\n","    data_min = 0\n","    data_max = 255\n","    X_test_norm = (X_test - data_min) / (data_max - data_min)\n","elif normalization_type == '-1':\n","    data_min = 0\n","    data_max = 255\n","    X_test_norm = 2 * ((X_test - data_min) / (data_max - data_min)) - 1\n","elif normalization_type == 'none':\n","    X_test_norm = X_test\n","else:\n","    raise ValueError(\"Unsupported normalization type. Choose '0-1' or '-1-1'.\")"],"metadata":{"id":"VSIzdkvtd9u0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["prediction = adapted_model.predict(X_test_norm)\n","\n","np.save('/content/drive/MyDrive/Meta_learning_research/Notebooks/predicts/'+name+\".npy\", prediction)\n","print('/content/drive/MyDrive/Meta_learning_research/Notebooks/predicts/'+name+\".npy\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LqDEgBIrGmQ-","executionInfo":{"status":"ok","timestamp":1714776489625,"user_tz":300,"elapsed":16855,"user":{"displayName":"Nattapon Jaroenchai","userId":"17092454241854925654"}},"outputId":"f348e6a4-e6ed-4813-dbf1-494c87cd7346"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["115/115 [==============================] - 5s 30ms/step\n","/content/drive/MyDrive/Meta_learning_research/Notebooks/predicts/maml_1_500_1_20240503_201907_best_model.npy\n"]}]},{"cell_type":"code","source":["print('/content/drive/MyDrive/Meta_learning_research/Notebooks/predicts/'+name+\".npy\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DeMBpzPB30D6","executionInfo":{"status":"ok","timestamp":1714444786166,"user_tz":300,"elapsed":163,"user":{"displayName":"Nattapon Jaroenchai","userId":"17092454241854925654"}},"outputId":"2ae780b3-dad9-4560-a335-3e078c28a95f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/Meta_learning_research/Notebooks/predicts/maml_1_500_1_20240430_013450_best_model.npy\n"]}]},{"cell_type":"markdown","source":["# Visualization for the input data"],"metadata":{"id":"dGxA0sAal0NT"}},{"cell_type":"code","source":["def visualize_images(image_stack, labels, num_images=25):\n","    \"\"\"\n","    Visualizes images with their respective channels and labels.\n","\n","    Args:\n","    - image_stack (numpy.ndarray): An array of shape (N, 224, 224, 8) where N is the number of images.\n","    - labels (numpy.ndarray): An array of labels of shape (N, 224, 224).\n","    - num_images (int): Number of images to visualize.\n","    \"\"\"\n","    fig, axs = plt.subplots(nrows=num_images, ncols=9, figsize=(18, 2 * num_images))\n","\n","    for i in range(min(num_images, image_stack.shape[0])):\n","        # Normalize each channel for visualization purposes\n","        for ch in range(8):\n","            axs[i, ch].imshow(image_stack[i, :, :, ch], cmap='gray', aspect='auto')\n","            axs[i, ch].axis('off')  # Turn off axis\n","        # Adding the label image in the last column\n","        axs[i, 8].imshow(labels[i], cmap='gray', aspect='auto')\n","        axs[i, 8].axis('off')\n","\n","    plt.subplots_adjust(wspace=0.05, hspace=0.05)\n","    plt.show()"],"metadata":{"id":"rvj7zA5tlztK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["eps_idx= 0\n","\n","visualize_images(meta_test_episodes[eps_idx][\"support_set_data\"], meta_test_episodes[eps_idx][\"support_set_labels\"], num_images=25)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"15rsIsJvFQRTfhjtvDwdz8FUCAPPqnD8P"},"id":"de9BBEtKJh9e","executionInfo":{"status":"ok","timestamp":1714774936639,"user_tz":300,"elapsed":46321,"user":{"displayName":"Nattapon Jaroenchai","userId":"17092454241854925654"}},"outputId":"9790d1b3-cd08-48e2-abf0-67dbd13df295"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"code","source":["eps_idx= 0\n","\n","visualize_images(meta_test_episodes[eps_idx][\"query_set_data\"], meta_test_episodes[eps_idx][\"query_set_labels\"], num_images=25)"],"metadata":{"id":"fGQx7Ji1qoEY"},"execution_count":null,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"L4","machine_shape":"hm","provenance":[],"collapsed_sections":["OLPZC3TV23BG","goGl3RvRSReK"],"mount_file_id":"1AOGc1N45yTqbd7k60CeDNVuDvKudnlRo","authorship_tag":"ABX9TyPjKzSWqZ9kdpF9JNx7klNX"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}