{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1v0gwWn9e3XfPxIL1wryiDqwHmBdTRaBT","timestamp":1692971781030}],"machine_shape":"hm","mount_file_id":"13scuEJU9L2ktFJEZVy_EctNsll-LpfOh","authorship_tag":"ABX9TyOBd9ayHcoWok6jEcrEBPr/"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Data Preparation\n","\n"],"metadata":{"id":"zlLDoeK6tkMR"}},{"cell_type":"code","source":["!cp '/content/drive/MyDrive/Meta_learning_research/Notebooks/data_util.py' .\n","from data_util import *"],"metadata":{"id":"ak9qhZdZQqZY","executionInfo":{"status":"ok","timestamp":1693496887832,"user_tz":300,"elapsed":363,"user":{"displayName":"Nattapon Jaroenchai","userId":"17092454241854925654"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["import os\n","import numpy as np\n","import tensorflow as tf"],"metadata":{"id":"6fR1ncyVGhps","executionInfo":{"status":"ok","timestamp":1693496889409,"user_tz":300,"elapsed":262,"user":{"displayName":"Nattapon Jaroenchai","userId":"17092454241854925654"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["class MetaDataLoader:\n","    def __init__(self, data_dir, num_samples_per_location=100):\n","        self.data_dir = data_dir\n","        self.num_samples_per_location = num_samples_per_location\n","\n","    def _load_and_process_data(self, locations):\n","        data_dict = {}\n","\n","        for location in locations:\n","            location_dir = os.path.join(self.data_dir, location)\n","\n","            train_data_path = os.path.join(location_dir, \"train_data.npy\")\n","            train_label_path = os.path.join(location_dir, \"train_label.npy\")\n","            vali_data_path = os.path.join(location_dir, \"vali_data.npy\")\n","            vali_label_path = os.path.join(location_dir, \"vali_label.npy\")\n","\n","            # Load training data and labels\n","            train_data = np.load(train_data_path)\n","            train_label = np.load(train_label_path)\n","\n","            # Load validation data and labels\n","            vali_data = np.load(vali_data_path)\n","            vali_label = np.load(vali_label_path)\n","\n","            # Store data and labels in the data_dict with location as key\n","            data_dict[location] = {\n","                'train_data': train_data,\n","                'train_label': train_label,\n","                'vali_data': vali_data,\n","                'vali_label': vali_label\n","            }\n","\n","        return data_dict\n","\n","    def _create_episode(self, locations):\n","\n","        data_dict = self._load_and_process_data(locations)\n","\n","        #--------- Create the support set -------------\n","        selected_data = []\n","        selected_labels = []\n","        for location in locations:\n","            selected_data.extend(data_dict[location]['train_data'][:num_samples_per_location])\n","            selected_labels.extend(data_dict[location]['train_label'][:num_samples_per_location])\n","\n","\n","        data = np.array(selected_data)\n","        labels = np.array(selected_labels)\n","\n","        # Shuffle the data and labels if needed\n","        indices = np.arange(data.shape[0])\n","        np.random.shuffle(indices)\n","        support_set_data = data[indices]\n","        support_set_labels = labels[indices]\n","\n","        #--------- End create the support set -------------\n","\n","        #--------- Create the query set -------------\n","        selected_data = []\n","        selected_labels = []\n","\n","        for location in locations:\n","            selected_data.extend(data_dict[location]['vali_data'][:num_samples_per_location])\n","            selected_labels.extend(data_dict[location]['vali_label'][:num_samples_per_location])\n","\n","        data = np.array(selected_data)\n","        labels = np.array(selected_labels)\n","\n","        # Shuffle the data and labels if needed\n","        indices = np.arange(data.shape[0])\n","        np.random.shuffle(indices)\n","        query_set_data = data[indices]\n","        query_set_labels = labels[indices]\n","\n","        #--------- End create the query set -------------\n","\n","        return support_set_data, support_set_labels, query_set_data, query_set_labels\n","\n","    def create_multi_episodes(self, num_episodes, locations):\n","        episodes = []\n","        for _ in range(num_episodes):\n","            support_set_data, support_set_labels, query_set_data, query_set_labels = self._create_episode(locations)\n","            episode = {\n","                \"support_set_data\": support_set_data,\n","                \"support_set_labels\": support_set_labels,\n","                \"query_set_data\": query_set_data,\n","                \"query_set_labels\": query_set_labels\n","            }\n","            episodes.append(episode)\n","        return episodes\n"],"metadata":{"id":"OFZIpmjftd8T","executionInfo":{"status":"ok","timestamp":1693493299119,"user_tz":300,"elapsed":4,"user":{"displayName":"Nattapon Jaroenchai","userId":"17092454241854925654"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["%cd '/content/drive/MyDrive/Meta_learning_research/Notebooks/'\n","data_dir = './samples/'  # Replace with the path to your directory containing numpy files\n","locations_meta_training = ['Alexander', 'Rowancreek']\n","locations_meta_testing = ['Covington']\n","num_samples_per_location = 100  # Configure the number of samples per location\n","num_episodes = 10  # Number of episodes\n","\n","data_loader = MetaDataLoader(data_dir, num_samples_per_location)\n","\n","# Create multi episodes for meta-training\n","episodes = data_loader.create_multi_episodes(num_episodes, locations_meta_training)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":373},"id":"sxaLqOcrjXk3","executionInfo":{"status":"error","timestamp":1693496972574,"user_tz":300,"elapsed":80116,"user":{"displayName":"Nattapon Jaroenchai","userId":"17092454241854925654"}},"outputId":"5f5fe721-08f7-4a4e-e651-1571c8bfee12"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/Meta_learning_research/Notebooks\n"]},{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-4-9b0cdea62081>\u001b[0m in \u001b[0;36m<cell line: 11>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# Create multi episodes for meta-training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mepisodes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_loader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_multi_episodes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_episodes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocations_meta_training\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/content/data_util.py\u001b[0m in \u001b[0;36mcreate_multi_episodes\u001b[0;34m(self, num_episodes, locations)\u001b[0m\n\u001b[1;32m     84\u001b[0m         \u001b[0mepisodes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_episodes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m             \u001b[0msupport_set_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msupport_set_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquery_set_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquery_set_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_episode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m             episode = {\n\u001b[1;32m     88\u001b[0m                 \u001b[0;34m\"support_set_data\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0msupport_set_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/data_util.py\u001b[0m in \u001b[0;36m_create_episode\u001b[0;34m(self, locations)\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0mselected_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mlocation\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlocations\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m             \u001b[0mselected_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlocation\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'train_data'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mnum_samples_per_location\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m             \u001b[0mselected_labels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlocation\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'train_label'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mnum_samples_per_location\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'num_samples_per_location' is not defined"]}]},{"cell_type":"code","source":["%cd '/content/drive/MyDrive/Meta_learning_research/Notebooks/'\n","import os\n","input_data = './samples/'\n","model_path = './models/'\n","prediction_path = './predicts/'\n","log_path = './logs/'\n","\n","# Create the folder if it does not exist\n","os.makedirs(input_data, exist_ok=True)\n","os.makedirs(model_path, exist_ok=True)\n","os.makedirs(prediction_path, exist_ok=True)\n"],"metadata":{"id":"hDnoIGNtC5PT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["episodes[2]['query_set_labels'].shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"q-0UAGPGGdU4","executionInfo":{"status":"ok","timestamp":1693493690429,"user_tz":300,"elapsed":320,"user":{"displayName":"Nattapon Jaroenchai","userId":"17092454241854925654"}},"outputId":"a3c5a934-91c3-4c14-b4dd-2754c38aa0a2"},"execution_count":15,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(130, 224, 224, 1)"]},"metadata":{},"execution_count":15}]}]}